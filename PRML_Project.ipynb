{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 17:20:13.482069: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733226613.502750  229141 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733226613.509061  229141 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 17:20:13.532552: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data from dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3'\n",
    "\n",
    "ptbxl_df = pd.read_csv(os.path.join(DATA_PATH, 'ptbxl_database.csv'))\n",
    "scp_statements = pd.read_csv(os.path.join(DATA_PATH, 'scp_statements.csv'), index_col=0)\n",
    "\n",
    "diagnostic_scps = scp_statements[scp_statements['diagnostic'] == 1].index.values\n",
    "\n",
    "scp_to_superclass = scp_statements['diagnostic_class'].to_dict()\n",
    "scp_to_subclass = scp_statements['diagnostic_subclass'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_df['scp_codes'] = ptbxl_df['scp_codes'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_diagnostic_labels(df, scp_codes, scp_to_agg):\n",
    "    df = df.copy()\n",
    "    def aggregate_labels(scp_codes_dict):\n",
    "        labels = set()\n",
    "        for code in scp_codes_dict.keys():\n",
    "            if code in scp_codes:\n",
    "                label = scp_to_agg.get(code)\n",
    "                if label:\n",
    "                    labels.add(label)\n",
    "        return list(labels)\n",
    "    df['diagnostic_labels'] = df['scp_codes'].apply(aggregate_labels)\n",
    "    return df\n",
    "\n",
    "ptbxl_df = aggregate_diagnostic_labels(ptbxl_df, diagnostic_scps, scp_to_superclass)\n",
    "ptbxl_df = ptbxl_df.rename(columns={'diagnostic_labels': 'superclass_labels'})\n",
    "\n",
    "ptbxl_df = aggregate_diagnostic_labels(ptbxl_df, diagnostic_scps, scp_to_subclass)\n",
    "ptbxl_df = ptbxl_df.rename(columns={'diagnostic_labels': 'subclass_labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_df = ptbxl_df[ptbxl_df['superclass_labels'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ptbxl_df[ptbxl_df.strat_fold <= 8]\n",
    "val_df = ptbxl_df[ptbxl_df.strat_fold == 9]\n",
    "test_df = ptbxl_df[ptbxl_df.strat_fold == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, sampling_rate, data_path):\n",
    "    data = []\n",
    "    i = 0\n",
    "    if sampling_rate == 100:\n",
    "        filenames = df['filename_lr'].values\n",
    "    else:\n",
    "        filenames = df['filename_hr'].values\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        signals, _ = wfdb.rdsamp(file_path)\n",
    "        data.append(signals)\n",
    "    return np.array(data)\n",
    "\n",
    "X_train = load_data(train_df, sampling_rate=100, data_path=DATA_PATH)\n",
    "X_val = load_data(val_df, sampling_rate=100, data_path=DATA_PATH)\n",
    "X_test = load_data(test_df, sampling_rate=100, data_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_super = train_df['superclass_labels'].values\n",
    "val_labels_super = val_df['superclass_labels'].values\n",
    "test_labels_super = test_df['superclass_labels'].values\n",
    "\n",
    "mlb_super = MultiLabelBinarizer()\n",
    "y_train_super = mlb_super.fit_transform(train_labels_super)\n",
    "y_val_super = mlb_super.transform(val_labels_super)\n",
    "y_test_super = mlb_super.transform(test_labels_super)\n",
    "classes_super = mlb_super.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_sub = train_df['subclass_labels'].values\n",
    "val_labels_sub = val_df['subclass_labels'].values\n",
    "test_labels_sub = test_df['subclass_labels'].values\n",
    "\n",
    "mlb_sub = MultiLabelBinarizer()\n",
    "y_train_sub = mlb_sub.fit_transform(train_labels_sub)\n",
    "y_val_sub = mlb_sub.transform(val_labels_sub)\n",
    "y_test_sub = mlb_sub.transform(test_labels_sub)\n",
    "classes_sub = mlb_sub.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_per_channel(X):\n",
    "    X = np.transpose(X, (0, 2, 1))\n",
    "    mean = np.mean(X, axis=(0, 2), keepdims=True)\n",
    "    std = np.std(X, axis=(0, 2), keepdims=True)\n",
    "    X = (X - mean) / std\n",
    "    X = np.transpose(X, (0, 2, 1))\n",
    "    return X\n",
    "\n",
    "X_train = normalize_data_per_channel(X_train)\n",
    "X_val = normalize_data_per_channel(X_val)\n",
    "X_test = normalize_data_per_channel(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts_super = np.sum(y_train_super, axis=0)\n",
    "total_samples_super = y_train_super.shape[0]\n",
    "\n",
    "class_weight_super = {}\n",
    "for i, count in enumerate(class_counts_super):\n",
    "    class_weight_super[i] = total_samples_super / (len(class_counts_super) * count)\n",
    "\n",
    "class_counts_sub = np.sum(y_train_sub, axis=0)\n",
    "total_samples_sub = y_train_sub.shape[0]\n",
    "\n",
    "class_weight_sub = {}\n",
    "for i, count in enumerate(class_counts_sub):\n",
    "    class_weight_sub[i] = total_samples_sub / (len(class_counts_sub) * count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_super = y_train_super.shape[1]\n",
    "class_totals = np.sum(y_train_super, axis=0)\n",
    "class_weights = class_totals.max() / class_totals\n",
    "weights_array = np.array(class_weights, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_sub = y_train_sub.shape[1]\n",
    "class_totals_sub = np.sum(y_train_sub, axis=0)\n",
    "class_weights_sub = class_totals_sub.max() / class_totals_sub\n",
    "weights_array_sub = np.array(class_weights_sub, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_super = y_train_super.astype(np.float32)\n",
    "y_val_super = y_val_super.astype(np.float32)\n",
    "y_test_super = y_test_super.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Entropy and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def weighted_binary_crossentropy(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        weights_cast = K.cast(weights, y_pred.dtype)\n",
    "        y_true = K.cast(y_true, y_pred.dtype)\n",
    "        \n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight_vector = y_true * weights_cast + (1 - y_true)\n",
    "        weighted_bce = weight_vector * bce\n",
    "        return K.mean(weighted_bce)\n",
    "    return loss\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred = K.round(y_pred)\n",
    "    \n",
    "    tp = K.sum(y_true * y_pred, axis=0)\n",
    "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
    "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def weighted_f1(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(y_true * y_pred, axis=0)\n",
    "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
    "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
    "    support = K.sum(y_true, axis=0)\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    weighted_f1 = K.sum(f1 * support) / K.sum(support)\n",
    "    weighted_f1 = tf.where(tf.math.is_nan(weighted_f1), 0.0, weighted_f1)\n",
    "    \n",
    "    return weighted_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv1D(64, kernel_size=7, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_resnet_model(input_shape, num_classes):\n",
    "#     inputs = layers.Input(shape=input_shape)\n",
    "#     x = layers.Conv1D(64, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation('relu')(x)\n",
    "#     x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "#     previous_filters = x.shape[-1]\n",
    "#     for filters in [64, 128, 256]:\n",
    "#         x_shortcut = x\n",
    "#         strides = 1\n",
    "#         if previous_filters != filters:\n",
    "#             strides = 2\n",
    "\n",
    "#         x = layers.Conv1D(filters, kernel_size=3, strides=strides, padding='same')(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "#         x = layers.Activation('relu')(x)\n",
    "#         x = layers.Conv1D(filters, kernel_size=3, padding='same')(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "        \n",
    "#         if previous_filters != filters or strides != 1:\n",
    "#             x_shortcut = layers.Conv1D(filters, kernel_size=1, strides=strides, padding='same')(x_shortcut)\n",
    "#             x_shortcut = layers.BatchNormalization()(x_shortcut)\n",
    "        \n",
    "#         x = layers.Add()([x, x_shortcut])\n",
    "#         x = layers.Activation('relu')(x)\n",
    "#         previous_filters = filters\n",
    "#     x = layers.GlobalAveragePooling1D()(x)\n",
    "#     outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "#     model = models.Model(inputs, outputs)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block_1d(x, filters, kernel_size=3, strides=1, downsample=False):\n",
    "    shortcut = x\n",
    "    \n",
    "    x = layers.Conv1D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv1D(filters, kernel_size=kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    if downsample or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv1D(filters, kernel_size=1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_resnet_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(64, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "    layers_filters = [64, 128, 256, 512]\n",
    "    layers_blocks = [3, 4, 6, 3]\n",
    "\n",
    "    for filters, num_blocks in zip(layers_filters, layers_blocks):\n",
    "        for i in range(num_blocks):\n",
    "            if i == 0 and filters != x.shape[-1]:\n",
    "                x = residual_block_1d(x, filters, strides=2, downsample=True)\n",
    "            else:\n",
    "                x = residual_block_1d(x, filters)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "def create_vit_model(input_shape, num_classes):\n",
    "    patch_size = 10 \n",
    "    num_patches = input_shape[0] // patch_size\n",
    "    projection_dim = 64\n",
    "    num_heads = 4\n",
    "    transformer_layers = 8\n",
    "    mlp_head_units = [256, 128]\n",
    "    dropout_rate = 0.1\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Reshape((num_patches, patch_size * input_shape[1]))(inputs)\n",
    "    x = layers.Dense(units=projection_dim)(x)\n",
    "    positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "    position_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)\n",
    "    x = x + position_embedding(positions)\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=dropout_rate\n",
    "        )(x1, x1)\n",
    "        x2 = layers.Add()([attention_output, x])\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=[projection_dim * 2, projection_dim], dropout_rate=dropout_rate)\n",
    "        x = layers.Add()([x3, x2])\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, class_weight, batch_size=64, epochs=25):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', macro_f1, weighted_f1]\n",
    "    )\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluating Models without CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733226681.640433  229141 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31139 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733226681.665186  229141 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31139 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733226681.666585  229141 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 31139 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733226681.667870  229141 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 31139 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0b:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733226681.669243  229141 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 31141 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:85:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733226681.670249  229141 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 31141 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733226681.671279  229141 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 31141 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733226681.672315  229141 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 31141 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733226688.318163  229912 service.cc:148] XLA service 0x7fbb70005b90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733226688.318211  229912 service.cc:156]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733226688.318217  229912 service.cc:156]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733226688.318222  229912 service.cc:156]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733226688.318226  229912 service.cc:156]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733226688.318230  229912 service.cc:156]   StreamExecutor device (4): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733226688.318233  229912 service.cc:156]   StreamExecutor device (5): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733226688.318238  229912 service.cc:156]   StreamExecutor device (6): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733226688.318242  229912 service.cc:156]   StreamExecutor device (7): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-12-03 17:21:28.458043: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1733226688.944224  229912 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 10/267\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.3824 - loss: 0.4175 - macro_f1: 0.3947 - weighted_f1: 0.4377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733226693.052912  229912 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m265/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6017 - loss: 0.3053 - macro_f1: 0.6144 - weighted_f1: 0.6526"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1733226698.917344  229914 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1733226699.210659  229914 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 45ms/step - accuracy: 0.6022 - loss: 0.3050 - macro_f1: 0.6149 - weighted_f1: 0.6531 - val_accuracy: 0.6622 - val_loss: 0.3488 - val_macro_f1: 0.6394 - val_weighted_f1: 0.6855 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6804 - loss: 0.2411 - macro_f1: 0.7122 - weighted_f1: 0.7431 - val_accuracy: 0.6962 - val_loss: 0.3128 - val_macro_f1: 0.6999 - val_weighted_f1: 0.7385 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7018 - loss: 0.2242 - macro_f1: 0.7296 - weighted_f1: 0.7600 - val_accuracy: 0.6580 - val_loss: 0.3201 - val_macro_f1: 0.6989 - val_weighted_f1: 0.7397 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7111 - loss: 0.2140 - macro_f1: 0.7433 - weighted_f1: 0.7741 - val_accuracy: 0.6817 - val_loss: 0.3005 - val_macro_f1: 0.7048 - val_weighted_f1: 0.7444 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7202 - loss: 0.2066 - macro_f1: 0.7542 - weighted_f1: 0.7847 - val_accuracy: 0.6925 - val_loss: 0.2934 - val_macro_f1: 0.6923 - val_weighted_f1: 0.7303 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7264 - loss: 0.2008 - macro_f1: 0.7616 - weighted_f1: 0.7915 - val_accuracy: 0.6692 - val_loss: 0.3194 - val_macro_f1: 0.6943 - val_weighted_f1: 0.7326 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7351 - loss: 0.1921 - macro_f1: 0.7729 - weighted_f1: 0.8024 - val_accuracy: 0.6957 - val_loss: 0.2852 - val_macro_f1: 0.7063 - val_weighted_f1: 0.7566 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7491 - loss: 0.1861 - macro_f1: 0.7795 - weighted_f1: 0.8085 - val_accuracy: 0.6538 - val_loss: 0.3123 - val_macro_f1: 0.6988 - val_weighted_f1: 0.7346 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7437 - loss: 0.1807 - macro_f1: 0.7870 - weighted_f1: 0.8148 - val_accuracy: 0.6673 - val_loss: 0.3308 - val_macro_f1: 0.7036 - val_weighted_f1: 0.7424 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7512 - loss: 0.1756 - macro_f1: 0.7937 - weighted_f1: 0.8194 - val_accuracy: 0.6803 - val_loss: 0.2933 - val_macro_f1: 0.7232 - val_weighted_f1: 0.7618 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7607 - loss: 0.1663 - macro_f1: 0.8040 - weighted_f1: 0.8297 - val_accuracy: 0.7036 - val_loss: 0.2891 - val_macro_f1: 0.7129 - val_weighted_f1: 0.7603 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7626 - loss: 0.1605 - macro_f1: 0.8067 - weighted_f1: 0.8318 - val_accuracy: 0.6859 - val_loss: 0.3121 - val_macro_f1: 0.7160 - val_weighted_f1: 0.7567 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7777 - loss: 0.1410 - macro_f1: 0.8329 - weighted_f1: 0.8567 - val_accuracy: 0.7027 - val_loss: 0.2830 - val_macro_f1: 0.7244 - val_weighted_f1: 0.7694 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7909 - loss: 0.1258 - macro_f1: 0.8507 - weighted_f1: 0.8714 - val_accuracy: 0.7111 - val_loss: 0.2908 - val_macro_f1: 0.7157 - val_weighted_f1: 0.7669 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7938 - loss: 0.1194 - macro_f1: 0.8631 - weighted_f1: 0.8788 - val_accuracy: 0.7130 - val_loss: 0.2936 - val_macro_f1: 0.7214 - val_weighted_f1: 0.7694 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7970 - loss: 0.1151 - macro_f1: 0.8687 - weighted_f1: 0.8856 - val_accuracy: 0.7134 - val_loss: 0.2983 - val_macro_f1: 0.7189 - val_weighted_f1: 0.7664 - learning_rate: 1.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8038 - loss: 0.1093 - macro_f1: 0.8745 - weighted_f1: 0.8917 - val_accuracy: 0.7032 - val_loss: 0.3009 - val_macro_f1: 0.7152 - val_weighted_f1: 0.7643 - learning_rate: 1.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8059 - loss: 0.1074 - macro_f1: 0.8810 - weighted_f1: 0.8950 - val_accuracy: 0.7032 - val_loss: 0.3083 - val_macro_f1: 0.7254 - val_weighted_f1: 0.7677 - learning_rate: 1.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8090 - loss: 0.1019 - macro_f1: 0.8836 - weighted_f1: 0.9002 - val_accuracy: 0.7036 - val_loss: 0.3081 - val_macro_f1: 0.7230 - val_weighted_f1: 0.7668 - learning_rate: 1.0000e-05\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8106 - loss: 0.1006 - macro_f1: 0.8864 - weighted_f1: 0.9004 - val_accuracy: 0.7027 - val_loss: 0.3099 - val_macro_f1: 0.7181 - val_weighted_f1: 0.7640 - learning_rate: 1.0000e-05\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8103 - loss: 0.0990 - macro_f1: 0.8877 - weighted_f1: 0.9032 - val_accuracy: 0.7036 - val_loss: 0.3096 - val_macro_f1: 0.7200 - val_weighted_f1: 0.7657 - learning_rate: 1.0000e-05\n",
      "Epoch 22/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8109 - loss: 0.0977 - macro_f1: 0.8891 - weighted_f1: 0.9020 - val_accuracy: 0.7036 - val_loss: 0.3101 - val_macro_f1: 0.7184 - val_weighted_f1: 0.7651 - learning_rate: 1.0000e-05\n",
      "Epoch 23/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8164 - loss: 0.0968 - macro_f1: 0.8896 - weighted_f1: 0.9038 - val_accuracy: 0.7046 - val_loss: 0.3117 - val_macro_f1: 0.7177 - val_weighted_f1: 0.7642 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fc02fe18b80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "num_classes_super = y_train_super.shape[1]\n",
    "\n",
    "cnn_super_model = create_cnn_model(input_shape, num_classes_super)\n",
    "train_model(cnn_super_model, X_train, y_train_super, X_val, y_val_super, class_weight_super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m265/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5555 - loss: 0.3932 - macro_f1: 0.5565 - weighted_f1: 0.5875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1733226865.964603  229914 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1733226866.192433  229914 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 106ms/step - accuracy: 0.5563 - loss: 0.3922 - macro_f1: 0.5573 - weighted_f1: 0.5884 - val_accuracy: 0.5955 - val_loss: 1.0710 - val_macro_f1: 0.5333 - val_weighted_f1: 0.5829 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6751 - loss: 0.2557 - macro_f1: 0.6908 - weighted_f1: 0.7241 - val_accuracy: 0.5144 - val_loss: 0.5218 - val_macro_f1: 0.5693 - val_weighted_f1: 0.6029 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7004 - loss: 0.2381 - macro_f1: 0.7135 - weighted_f1: 0.7466 - val_accuracy: 0.6482 - val_loss: 0.4249 - val_macro_f1: 0.6234 - val_weighted_f1: 0.6697 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7054 - loss: 0.2240 - macro_f1: 0.7302 - weighted_f1: 0.7649 - val_accuracy: 0.6733 - val_loss: 0.3693 - val_macro_f1: 0.6687 - val_weighted_f1: 0.7153 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7111 - loss: 0.2213 - macro_f1: 0.7347 - weighted_f1: 0.7651 - val_accuracy: 0.6934 - val_loss: 0.3233 - val_macro_f1: 0.6901 - val_weighted_f1: 0.7271 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.7148 - loss: 0.2177 - macro_f1: 0.7457 - weighted_f1: 0.7737 - val_accuracy: 0.6901 - val_loss: 0.3438 - val_macro_f1: 0.6815 - val_weighted_f1: 0.7259 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7262 - loss: 0.2074 - macro_f1: 0.7583 - weighted_f1: 0.7878 - val_accuracy: 0.6123 - val_loss: 0.4426 - val_macro_f1: 0.6590 - val_weighted_f1: 0.6733 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7320 - loss: 0.1992 - macro_f1: 0.7627 - weighted_f1: 0.7918 - val_accuracy: 0.6733 - val_loss: 0.3366 - val_macro_f1: 0.7100 - val_weighted_f1: 0.7434 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7333 - loss: 0.1956 - macro_f1: 0.7697 - weighted_f1: 0.7953 - val_accuracy: 0.6915 - val_loss: 0.3734 - val_macro_f1: 0.6617 - val_weighted_f1: 0.7198 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7392 - loss: 0.1894 - macro_f1: 0.7774 - weighted_f1: 0.8042 - val_accuracy: 0.6971 - val_loss: 0.3248 - val_macro_f1: 0.7072 - val_weighted_f1: 0.7518 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7671 - loss: 0.1706 - macro_f1: 0.7994 - weighted_f1: 0.8265 - val_accuracy: 0.7055 - val_loss: 0.2751 - val_macro_f1: 0.7268 - val_weighted_f1: 0.7701 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7775 - loss: 0.1493 - macro_f1: 0.8270 - weighted_f1: 0.8475 - val_accuracy: 0.7032 - val_loss: 0.2879 - val_macro_f1: 0.7220 - val_weighted_f1: 0.7671 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7817 - loss: 0.1395 - macro_f1: 0.8406 - weighted_f1: 0.8606 - val_accuracy: 0.6943 - val_loss: 0.2966 - val_macro_f1: 0.7180 - val_weighted_f1: 0.7640 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7888 - loss: 0.1307 - macro_f1: 0.8457 - weighted_f1: 0.8666 - val_accuracy: 0.6962 - val_loss: 0.3272 - val_macro_f1: 0.7045 - val_weighted_f1: 0.7563 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.8014 - loss: 0.1190 - macro_f1: 0.8643 - weighted_f1: 0.8828 - val_accuracy: 0.6859 - val_loss: 0.3411 - val_macro_f1: 0.7196 - val_weighted_f1: 0.7606 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.8121 - loss: 0.1091 - macro_f1: 0.8749 - weighted_f1: 0.8914 - val_accuracy: 0.6934 - val_loss: 0.3574 - val_macro_f1: 0.7124 - val_weighted_f1: 0.7574 - learning_rate: 1.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.8173 - loss: 0.0924 - macro_f1: 0.8941 - weighted_f1: 0.9098 - val_accuracy: 0.7004 - val_loss: 0.3664 - val_macro_f1: 0.7220 - val_weighted_f1: 0.7638 - learning_rate: 1.0000e-05\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.8236 - loss: 0.0832 - macro_f1: 0.9068 - weighted_f1: 0.9196 - val_accuracy: 0.6985 - val_loss: 0.4038 - val_macro_f1: 0.7109 - val_weighted_f1: 0.7579 - learning_rate: 1.0000e-05\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.8265 - loss: 0.0799 - macro_f1: 0.9118 - weighted_f1: 0.9239 - val_accuracy: 0.6976 - val_loss: 0.4246 - val_macro_f1: 0.7136 - val_weighted_f1: 0.7596 - learning_rate: 1.0000e-05\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.8286 - loss: 0.0744 - macro_f1: 0.9169 - weighted_f1: 0.9286 - val_accuracy: 0.6943 - val_loss: 0.4352 - val_macro_f1: 0.7075 - val_weighted_f1: 0.7550 - learning_rate: 1.0000e-05\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.8285 - loss: 0.0721 - macro_f1: 0.9201 - weighted_f1: 0.9301 - val_accuracy: 0.6938 - val_loss: 0.4404 - val_macro_f1: 0.7072 - val_weighted_f1: 0.7547 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbe7860a940>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_super_model = create_resnet_model(input_shape, num_classes_super)\n",
    "train_model(resnet_super_model, X_train, y_train_super, X_val, y_val_super, class_weight_super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 118ms/step - accuracy: 0.4420 - loss: 0.4268 - macro_f1: 0.4150 - weighted_f1: 0.4594 - val_accuracy: 0.5107 - val_loss: 0.4518 - val_macro_f1: 0.5193 - val_weighted_f1: 0.5729 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6263 - loss: 0.2935 - macro_f1: 0.6247 - weighted_f1: 0.6632 - val_accuracy: 0.5564 - val_loss: 0.3822 - val_macro_f1: 0.6193 - val_weighted_f1: 0.6567 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6677 - loss: 0.2576 - macro_f1: 0.6801 - weighted_f1: 0.7169 - val_accuracy: 0.6440 - val_loss: 0.3314 - val_macro_f1: 0.6637 - val_weighted_f1: 0.7059 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.6913 - loss: 0.2321 - macro_f1: 0.7136 - weighted_f1: 0.7476 - val_accuracy: 0.6580 - val_loss: 0.3233 - val_macro_f1: 0.6785 - val_weighted_f1: 0.7219 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7003 - loss: 0.2178 - macro_f1: 0.7426 - weighted_f1: 0.7692 - val_accuracy: 0.6477 - val_loss: 0.3329 - val_macro_f1: 0.6844 - val_weighted_f1: 0.7177 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7234 - loss: 0.2020 - macro_f1: 0.7659 - weighted_f1: 0.7927 - val_accuracy: 0.6584 - val_loss: 0.3268 - val_macro_f1: 0.6648 - val_weighted_f1: 0.7140 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7306 - loss: 0.1891 - macro_f1: 0.7760 - weighted_f1: 0.8018 - val_accuracy: 0.6463 - val_loss: 0.3489 - val_macro_f1: 0.6732 - val_weighted_f1: 0.7206 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7428 - loss: 0.1726 - macro_f1: 0.7975 - weighted_f1: 0.8193 - val_accuracy: 0.6622 - val_loss: 0.3569 - val_macro_f1: 0.6615 - val_weighted_f1: 0.7121 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.7478 - loss: 0.1640 - macro_f1: 0.8105 - weighted_f1: 0.8316 - val_accuracy: 0.6519 - val_loss: 0.3625 - val_macro_f1: 0.6537 - val_weighted_f1: 0.7053 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7859 - loss: 0.1312 - macro_f1: 0.8505 - weighted_f1: 0.8677 - val_accuracy: 0.6719 - val_loss: 0.3771 - val_macro_f1: 0.6870 - val_weighted_f1: 0.7323 - learning_rate: 1.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7987 - loss: 0.1099 - macro_f1: 0.8738 - weighted_f1: 0.8870 - val_accuracy: 0.6682 - val_loss: 0.3907 - val_macro_f1: 0.6836 - val_weighted_f1: 0.7286 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.8028 - loss: 0.1026 - macro_f1: 0.8887 - weighted_f1: 0.8995 - val_accuracy: 0.6654 - val_loss: 0.4006 - val_macro_f1: 0.6777 - val_weighted_f1: 0.7263 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.8043 - loss: 0.0974 - macro_f1: 0.8942 - weighted_f1: 0.9043 - val_accuracy: 0.6673 - val_loss: 0.4119 - val_macro_f1: 0.6807 - val_weighted_f1: 0.7263 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.8119 - loss: 0.0900 - macro_f1: 0.8994 - weighted_f1: 0.9096 - val_accuracy: 0.6678 - val_loss: 0.4224 - val_macro_f1: 0.6817 - val_weighted_f1: 0.7267 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbd8c253e50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_super_model = create_vit_model(input_shape, num_classes_super)\n",
    "train_model(vit_super_model, X_train, y_train_super, X_val, y_val_super, class_weight_super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - accuracy: 0.3823 - loss: 0.1309 - macro_f1: 0.1113 - weighted_f1: 0.2219 - val_accuracy: 0.3621 - val_loss: 0.1663 - val_macro_f1: 0.1498 - val_weighted_f1: 0.2451 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4715 - loss: 0.0854 - macro_f1: 0.2041 - weighted_f1: 0.3693 - val_accuracy: 0.4627 - val_loss: 0.1446 - val_macro_f1: 0.2073 - val_weighted_f1: 0.4047 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.5154 - loss: 0.0739 - macro_f1: 0.2442 - weighted_f1: 0.4454 - val_accuracy: 0.2973 - val_loss: 0.1852 - val_macro_f1: 0.1557 - val_weighted_f1: 0.2704 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.5374 - loss: 0.0690 - macro_f1: 0.2696 - weighted_f1: 0.4851 - val_accuracy: 0.4012 - val_loss: 0.1543 - val_macro_f1: 0.1862 - val_weighted_f1: 0.3593 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5244 - loss: 0.0658 - macro_f1: 0.2851 - weighted_f1: 0.4897 - val_accuracy: 0.5326 - val_loss: 0.1258 - val_macro_f1: 0.2663 - val_weighted_f1: 0.5316 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5530 - loss: 0.0604 - macro_f1: 0.3085 - weighted_f1: 0.5456 - val_accuracy: 0.5382 - val_loss: 0.1202 - val_macro_f1: 0.2669 - val_weighted_f1: 0.5167 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5772 - loss: 0.0558 - macro_f1: 0.3242 - weighted_f1: 0.5677 - val_accuracy: 0.5755 - val_loss: 0.1171 - val_macro_f1: 0.2800 - val_weighted_f1: 0.5552 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5936 - loss: 0.0512 - macro_f1: 0.3430 - weighted_f1: 0.6062 - val_accuracy: 0.5391 - val_loss: 0.1244 - val_macro_f1: 0.2862 - val_weighted_f1: 0.5380 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5970 - loss: 0.0475 - macro_f1: 0.3567 - weighted_f1: 0.6158 - val_accuracy: 0.5666 - val_loss: 0.1167 - val_macro_f1: 0.2936 - val_weighted_f1: 0.5471 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.5958 - loss: 0.0477 - macro_f1: 0.3585 - weighted_f1: 0.6149 - val_accuracy: 0.5582 - val_loss: 0.1147 - val_macro_f1: 0.2854 - val_weighted_f1: 0.5385 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6126 - loss: 0.0447 - macro_f1: 0.3853 - weighted_f1: 0.6338 - val_accuracy: 0.5713 - val_loss: 0.1138 - val_macro_f1: 0.2998 - val_weighted_f1: 0.5645 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6124 - loss: 0.0450 - macro_f1: 0.3816 - weighted_f1: 0.6341 - val_accuracy: 0.5792 - val_loss: 0.1125 - val_macro_f1: 0.2861 - val_weighted_f1: 0.5743 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6102 - loss: 0.0456 - macro_f1: 0.3916 - weighted_f1: 0.6444 - val_accuracy: 0.5736 - val_loss: 0.1158 - val_macro_f1: 0.3090 - val_weighted_f1: 0.5771 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6236 - loss: 0.0409 - macro_f1: 0.3992 - weighted_f1: 0.6580 - val_accuracy: 0.5946 - val_loss: 0.1075 - val_macro_f1: 0.3336 - val_weighted_f1: 0.6132 - learning_rate: 0.0010\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6376 - loss: 0.0383 - macro_f1: 0.4209 - weighted_f1: 0.6784 - val_accuracy: 0.5974 - val_loss: 0.1123 - val_macro_f1: 0.3158 - val_weighted_f1: 0.6088 - learning_rate: 0.0010\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6530 - loss: 0.0348 - macro_f1: 0.4374 - weighted_f1: 0.6997 - val_accuracy: 0.5927 - val_loss: 0.1132 - val_macro_f1: 0.3387 - val_weighted_f1: 0.6348 - learning_rate: 0.0010\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6608 - loss: 0.0333 - macro_f1: 0.4517 - weighted_f1: 0.7114 - val_accuracy: 0.5829 - val_loss: 0.1152 - val_macro_f1: 0.3146 - val_weighted_f1: 0.5797 - learning_rate: 0.0010\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6666 - loss: 0.0313 - macro_f1: 0.4639 - weighted_f1: 0.7219 - val_accuracy: 0.5527 - val_loss: 0.1191 - val_macro_f1: 0.3312 - val_weighted_f1: 0.5931 - learning_rate: 0.0010\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6626 - loss: 0.0301 - macro_f1: 0.4754 - weighted_f1: 0.7313 - val_accuracy: 0.6295 - val_loss: 0.1189 - val_macro_f1: 0.2910 - val_weighted_f1: 0.5916 - learning_rate: 0.0010\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7014 - loss: 0.0263 - macro_f1: 0.5066 - weighted_f1: 0.7638 - val_accuracy: 0.6202 - val_loss: 0.1075 - val_macro_f1: 0.3444 - val_weighted_f1: 0.6455 - learning_rate: 1.0000e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7081 - loss: 0.0219 - macro_f1: 0.5311 - weighted_f1: 0.7885 - val_accuracy: 0.6295 - val_loss: 0.1090 - val_macro_f1: 0.3457 - val_weighted_f1: 0.6486 - learning_rate: 1.0000e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7111 - loss: 0.0205 - macro_f1: 0.5337 - weighted_f1: 0.7925 - val_accuracy: 0.6319 - val_loss: 0.1098 - val_macro_f1: 0.3344 - val_weighted_f1: 0.6428 - learning_rate: 1.0000e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7171 - loss: 0.0203 - macro_f1: 0.5343 - weighted_f1: 0.7994 - val_accuracy: 0.6295 - val_loss: 0.1101 - val_macro_f1: 0.3409 - val_weighted_f1: 0.6436 - learning_rate: 1.0000e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7210 - loss: 0.0200 - macro_f1: 0.5492 - weighted_f1: 0.8007 - val_accuracy: 0.6328 - val_loss: 0.1119 - val_macro_f1: 0.3389 - val_weighted_f1: 0.6442 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbc5808e9a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes_sub = y_train_sub.shape[1]\n",
    "cnn_sub_model = create_cnn_model(input_shape, num_classes_sub)\n",
    "train_model(cnn_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 91ms/step - accuracy: 0.2740 - loss: 0.1465 - macro_f1: 0.0484 - weighted_f1: 0.0839 - val_accuracy: 0.2050 - val_loss: 0.1911 - val_macro_f1: 0.0555 - val_weighted_f1: 0.0781 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4464 - loss: 0.0970 - macro_f1: 0.1237 - weighted_f1: 0.2369 - val_accuracy: 0.2768 - val_loss: 0.2235 - val_macro_f1: 0.1136 - val_weighted_f1: 0.1117 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5034 - loss: 0.0870 - macro_f1: 0.1644 - weighted_f1: 0.3132 - val_accuracy: 0.4581 - val_loss: 0.1786 - val_macro_f1: 0.1364 - val_weighted_f1: 0.1981 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.5026 - loss: 0.0811 - macro_f1: 0.1996 - weighted_f1: 0.3679 - val_accuracy: 0.5336 - val_loss: 0.1388 - val_macro_f1: 0.1746 - val_weighted_f1: 0.3973 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4842 - loss: 0.0797 - macro_f1: 0.2019 - weighted_f1: 0.3505 - val_accuracy: 0.2521 - val_loss: 0.1999 - val_macro_f1: 0.1254 - val_weighted_f1: 0.1825 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4514 - loss: 0.0884 - macro_f1: 0.1795 - weighted_f1: 0.3169 - val_accuracy: 0.4320 - val_loss: 0.1506 - val_macro_f1: 0.1789 - val_weighted_f1: 0.3293 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4927 - loss: 0.0783 - macro_f1: 0.2056 - weighted_f1: 0.3753 - val_accuracy: 0.4977 - val_loss: 0.1380 - val_macro_f1: 0.2161 - val_weighted_f1: 0.4339 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4914 - loss: 0.0737 - macro_f1: 0.2326 - weighted_f1: 0.4133 - val_accuracy: 0.1342 - val_loss: 0.2160 - val_macro_f1: 0.0915 - val_weighted_f1: 0.0980 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4884 - loss: 0.0737 - macro_f1: 0.2284 - weighted_f1: 0.3977 - val_accuracy: 0.4739 - val_loss: 0.1378 - val_macro_f1: 0.2027 - val_weighted_f1: 0.4091 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5209 - loss: 0.0697 - macro_f1: 0.2628 - weighted_f1: 0.4649 - val_accuracy: 0.3593 - val_loss: 0.1525 - val_macro_f1: 0.1652 - val_weighted_f1: 0.2094 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5114 - loss: 0.0645 - macro_f1: 0.2681 - weighted_f1: 0.4482 - val_accuracy: 0.3784 - val_loss: 0.1575 - val_macro_f1: 0.1989 - val_weighted_f1: 0.3431 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5360 - loss: 0.0641 - macro_f1: 0.2709 - weighted_f1: 0.4859 - val_accuracy: 0.5345 - val_loss: 0.1213 - val_macro_f1: 0.2580 - val_weighted_f1: 0.4977 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5552 - loss: 0.0584 - macro_f1: 0.3006 - weighted_f1: 0.5368 - val_accuracy: 0.5200 - val_loss: 0.1284 - val_macro_f1: 0.2392 - val_weighted_f1: 0.4471 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5633 - loss: 0.0566 - macro_f1: 0.3131 - weighted_f1: 0.5426 - val_accuracy: 0.5662 - val_loss: 0.1151 - val_macro_f1: 0.2697 - val_weighted_f1: 0.5205 - learning_rate: 0.0010\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5644 - loss: 0.0544 - macro_f1: 0.3267 - weighted_f1: 0.5617 - val_accuracy: 0.5457 - val_loss: 0.1230 - val_macro_f1: 0.2709 - val_weighted_f1: 0.5075 - learning_rate: 0.0010\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5666 - loss: 0.0551 - macro_f1: 0.3204 - weighted_f1: 0.5612 - val_accuracy: 0.3103 - val_loss: 0.2052 - val_macro_f1: 0.2387 - val_weighted_f1: 0.3479 - learning_rate: 0.0010\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5667 - loss: 0.0556 - macro_f1: 0.3257 - weighted_f1: 0.5599 - val_accuracy: 0.5242 - val_loss: 0.1269 - val_macro_f1: 0.2824 - val_weighted_f1: 0.4980 - learning_rate: 0.0010\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5775 - loss: 0.0510 - macro_f1: 0.3518 - weighted_f1: 0.5905 - val_accuracy: 0.5527 - val_loss: 0.1212 - val_macro_f1: 0.2919 - val_weighted_f1: 0.5600 - learning_rate: 0.0010\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5950 - loss: 0.0468 - macro_f1: 0.3640 - weighted_f1: 0.6151 - val_accuracy: 0.5499 - val_loss: 0.1270 - val_macro_f1: 0.2914 - val_weighted_f1: 0.5539 - learning_rate: 0.0010\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6163 - loss: 0.0455 - macro_f1: 0.3790 - weighted_f1: 0.6373 - val_accuracy: 0.6011 - val_loss: 0.1047 - val_macro_f1: 0.3174 - val_weighted_f1: 0.6096 - learning_rate: 1.0000e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6247 - loss: 0.0390 - macro_f1: 0.4023 - weighted_f1: 0.6643 - val_accuracy: 0.6067 - val_loss: 0.1065 - val_macro_f1: 0.3233 - val_weighted_f1: 0.6171 - learning_rate: 1.0000e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6266 - loss: 0.0390 - macro_f1: 0.4230 - weighted_f1: 0.6753 - val_accuracy: 0.6118 - val_loss: 0.1063 - val_macro_f1: 0.3234 - val_weighted_f1: 0.6239 - learning_rate: 1.0000e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6331 - loss: 0.0364 - macro_f1: 0.4265 - weighted_f1: 0.6860 - val_accuracy: 0.5951 - val_loss: 0.1086 - val_macro_f1: 0.3274 - val_weighted_f1: 0.6185 - learning_rate: 1.0000e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6413 - loss: 0.0352 - macro_f1: 0.4391 - weighted_f1: 0.6964 - val_accuracy: 0.6030 - val_loss: 0.1084 - val_macro_f1: 0.3385 - val_weighted_f1: 0.6333 - learning_rate: 1.0000e-04\n",
      "Epoch 25/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6440 - loss: 0.0342 - macro_f1: 0.4346 - weighted_f1: 0.6983 - val_accuracy: 0.5909 - val_loss: 0.1110 - val_macro_f1: 0.3356 - val_weighted_f1: 0.6279 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbc145fe640>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_sub_model = create_resnet_model(input_shape, num_classes_sub)\n",
    "train_model(resnet_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 115ms/step - accuracy: 0.1579 - loss: 0.1527 - macro_f1: 0.0517 - weighted_f1: 0.0853 - val_accuracy: 0.4245 - val_loss: 0.1650 - val_macro_f1: 0.0595 - val_weighted_f1: 0.2446 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.3711 - loss: 0.0892 - macro_f1: 0.1295 - weighted_f1: 0.2427 - val_accuracy: 0.4441 - val_loss: 0.1643 - val_macro_f1: 0.1521 - val_weighted_f1: 0.3687 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.4623 - loss: 0.0721 - macro_f1: 0.2234 - weighted_f1: 0.3966 - val_accuracy: 0.4399 - val_loss: 0.1532 - val_macro_f1: 0.1934 - val_weighted_f1: 0.4167 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.5217 - loss: 0.0584 - macro_f1: 0.2868 - weighted_f1: 0.4818 - val_accuracy: 0.4753 - val_loss: 0.1505 - val_macro_f1: 0.1952 - val_weighted_f1: 0.4106 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.5506 - loss: 0.0492 - macro_f1: 0.3354 - weighted_f1: 0.5426 - val_accuracy: 0.5135 - val_loss: 0.1519 - val_macro_f1: 0.2025 - val_weighted_f1: 0.4536 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.5822 - loss: 0.0435 - macro_f1: 0.3667 - weighted_f1: 0.5906 - val_accuracy: 0.5112 - val_loss: 0.1451 - val_macro_f1: 0.2420 - val_weighted_f1: 0.5079 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6056 - loss: 0.0364 - macro_f1: 0.4154 - weighted_f1: 0.6364 - val_accuracy: 0.5382 - val_loss: 0.1463 - val_macro_f1: 0.2437 - val_weighted_f1: 0.5365 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6354 - loss: 0.0326 - macro_f1: 0.4463 - weighted_f1: 0.6785 - val_accuracy: 0.4897 - val_loss: 0.1557 - val_macro_f1: 0.2242 - val_weighted_f1: 0.4724 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6468 - loss: 0.0294 - macro_f1: 0.4650 - weighted_f1: 0.6948 - val_accuracy: 0.4860 - val_loss: 0.1565 - val_macro_f1: 0.2298 - val_weighted_f1: 0.4940 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6625 - loss: 0.0278 - macro_f1: 0.4853 - weighted_f1: 0.7219 - val_accuracy: 0.5368 - val_loss: 0.1568 - val_macro_f1: 0.2481 - val_weighted_f1: 0.5292 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6649 - loss: 0.0243 - macro_f1: 0.5111 - weighted_f1: 0.7351 - val_accuracy: 0.5312 - val_loss: 0.1610 - val_macro_f1: 0.2453 - val_weighted_f1: 0.5221 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7147 - loss: 0.0186 - macro_f1: 0.5471 - weighted_f1: 0.7934 - val_accuracy: 0.5429 - val_loss: 0.1592 - val_macro_f1: 0.2569 - val_weighted_f1: 0.5452 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7291 - loss: 0.0154 - macro_f1: 0.5739 - weighted_f1: 0.8208 - val_accuracy: 0.5489 - val_loss: 0.1612 - val_macro_f1: 0.2594 - val_weighted_f1: 0.5513 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7420 - loss: 0.0145 - macro_f1: 0.5885 - weighted_f1: 0.8371 - val_accuracy: 0.5429 - val_loss: 0.1647 - val_macro_f1: 0.2606 - val_weighted_f1: 0.5514 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7435 - loss: 0.0137 - macro_f1: 0.5818 - weighted_f1: 0.8404 - val_accuracy: 0.5433 - val_loss: 0.1666 - val_macro_f1: 0.2607 - val_weighted_f1: 0.5460 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7432 - loss: 0.0135 - macro_f1: 0.5930 - weighted_f1: 0.8437 - val_accuracy: 0.5564 - val_loss: 0.1672 - val_macro_f1: 0.2613 - val_weighted_f1: 0.5551 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbb7f5c9730>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_sub_model = create_vit_model(input_shape, num_classes_sub)\n",
    "train_model(vit_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, classes):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_threshold = (y_pred >= 0.5).astype(int)\n",
    "    report = classification_report(y_test, y_pred_threshold, target_names=classes, zero_division=0, output_dict=True)\n",
    "    print(classification_report(y_test, y_pred_threshold, target_names=classes, zero_division=0))\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.82      0.72      0.77       496\n",
      "         HYP       0.69      0.52      0.59       262\n",
      "          MI       0.82      0.69      0.75       550\n",
      "        NORM       0.84      0.89      0.87       963\n",
      "        STTC       0.76      0.75      0.75       521\n",
      "\n",
      "   micro avg       0.81      0.76      0.78      2792\n",
      "   macro avg       0.79      0.71      0.75      2792\n",
      "weighted avg       0.80      0.76      0.78      2792\n",
      " samples avg       0.79      0.78      0.77      2792\n",
      "\n",
      "ResNet Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.81      0.69      0.75       496\n",
      "         HYP       0.76      0.48      0.59       262\n",
      "          MI       0.78      0.67      0.72       550\n",
      "        NORM       0.85      0.86      0.85       963\n",
      "        STTC       0.72      0.78      0.75       521\n",
      "\n",
      "   micro avg       0.80      0.74      0.77      2792\n",
      "   macro avg       0.78      0.70      0.73      2792\n",
      "weighted avg       0.80      0.74      0.76      2792\n",
      " samples avg       0.78      0.77      0.76      2792\n",
      "\n",
      "ViT Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.84      0.53      0.65       496\n",
      "         HYP       0.68      0.42      0.52       262\n",
      "          MI       0.78      0.51      0.62       550\n",
      "        NORM       0.79      0.86      0.82       963\n",
      "        STTC       0.68      0.77      0.72       521\n",
      "\n",
      "   micro avg       0.76      0.68      0.72      2792\n",
      "   macro avg       0.75      0.62      0.67      2792\n",
      "weighted avg       0.77      0.68      0.71      2792\n",
      " samples avg       0.73      0.71      0.70      2792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN Superdiagnostic Classification Report:\")\n",
    "cnn_super_report = evaluate_model(cnn_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ResNet Superdiagnostic Classification Report:\")\n",
    "resnet_super_report = evaluate_model(resnet_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ViT Superdiagnostic Classification Report:\")\n",
    "vit_super_report = evaluate_model(vit_super_model, X_test, y_test_super, classes_super)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Subdiagnostic Classification Report:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.91      0.43      0.59       306\n",
      "       CLBBB       0.88      0.96      0.92        54\n",
      "       CRBBB       0.80      0.91      0.85        54\n",
      "       ILBBB       0.00      0.00      0.00         8\n",
      "         IMI       0.76      0.47      0.58       327\n",
      "       IRBBB       0.61      0.67      0.64       112\n",
      "        ISCA       0.41      0.26      0.32        93\n",
      "        ISCI       0.34      0.28      0.31        40\n",
      "        ISC_       0.73      0.48      0.58       128\n",
      "        IVCD       0.12      0.03      0.04        79\n",
      "   LAFB/LPFB       0.66      0.82      0.73       179\n",
      "     LAO/LAE       0.20      0.07      0.11        42\n",
      "         LMI       0.10      0.05      0.07        20\n",
      "         LVH       0.72      0.57      0.64       214\n",
      "        NORM       0.87      0.77      0.82       963\n",
      "        NST_       0.22      0.17      0.19        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.32      0.60      0.41        10\n",
      "         RVH       0.33      0.17      0.22        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.53      0.26      0.35       222\n",
      "         WPW       0.67      0.25      0.36         8\n",
      "        _AVB       0.55      0.48      0.51        82\n",
      "\n",
      "   micro avg       0.73      0.56      0.63      3034\n",
      "   macro avg       0.47      0.38      0.40      3034\n",
      "weighted avg       0.71      0.56      0.61      3034\n",
      " samples avg       0.62      0.60      0.59      3034\n",
      "\n",
      "ResNet Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.82      0.49      0.61       306\n",
      "       CLBBB       0.94      0.91      0.92        54\n",
      "       CRBBB       0.76      0.93      0.83        54\n",
      "       ILBBB       0.30      0.38      0.33         8\n",
      "         IMI       0.68      0.53      0.59       327\n",
      "       IRBBB       0.56      0.60      0.58       112\n",
      "        ISCA       0.39      0.14      0.21        93\n",
      "        ISCI       0.59      0.25      0.35        40\n",
      "        ISC_       0.70      0.52      0.59       128\n",
      "        IVCD       0.22      0.03      0.05        79\n",
      "   LAFB/LPFB       0.82      0.70      0.75       179\n",
      "     LAO/LAE       0.00      0.00      0.00        42\n",
      "         LMI       0.08      0.05      0.06        20\n",
      "         LVH       0.69      0.54      0.61       214\n",
      "        NORM       0.89      0.72      0.79       963\n",
      "        NST_       0.23      0.13      0.17        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.31      0.40      0.35        10\n",
      "         RVH       0.00      0.00      0.00        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.56      0.35      0.43       222\n",
      "         WPW       1.00      0.50      0.67         8\n",
      "        _AVB       0.57      0.40      0.47        82\n",
      "\n",
      "   micro avg       0.74      0.54      0.63      3034\n",
      "   macro avg       0.48      0.37      0.41      3034\n",
      "weighted avg       0.71      0.54      0.61      3034\n",
      " samples avg       0.61      0.58      0.58      3034\n",
      "\n",
      "ViT Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.65      0.46      0.54       306\n",
      "       CLBBB       0.80      0.94      0.86        54\n",
      "       CRBBB       0.75      0.83      0.79        54\n",
      "       ILBBB       0.00      0.00      0.00         8\n",
      "         IMI       0.68      0.37      0.48       327\n",
      "       IRBBB       0.56      0.30      0.39       112\n",
      "        ISCA       0.24      0.04      0.07        93\n",
      "        ISCI       0.40      0.05      0.09        40\n",
      "        ISC_       0.55      0.52      0.54       128\n",
      "        IVCD       0.08      0.03      0.04        79\n",
      "   LAFB/LPFB       0.73      0.57      0.64       179\n",
      "     LAO/LAE       0.06      0.05      0.05        42\n",
      "         LMI       0.25      0.05      0.08        20\n",
      "         LVH       0.57      0.58      0.58       214\n",
      "        NORM       0.82      0.58      0.68       963\n",
      "        NST_       0.24      0.05      0.09        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.00      0.00      0.00        10\n",
      "         RVH       0.50      0.08      0.14        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.34      0.51      0.41       222\n",
      "         WPW       0.00      0.00      0.00         8\n",
      "        _AVB       0.04      0.02      0.03        82\n",
      "\n",
      "   micro avg       0.61      0.45      0.52      3034\n",
      "   macro avg       0.36      0.26      0.28      3034\n",
      "weighted avg       0.60      0.45      0.51      3034\n",
      " samples avg       0.49      0.47      0.47      3034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN Subdiagnostic Classification Report:\")\n",
    "cnn_sub_report = evaluate_model(cnn_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ResNet Subdiagnostic Classification Report:\")\n",
    "resnet_sub_report = evaluate_model(resnet_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ViT Subdiagnostic Classification Report:\")\n",
    "vit_sub_report = evaluate_model(vit_sub_model, X_test, y_test_sub, classes_sub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining and Training on LwF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "Working on CNN for LwF Now:\n",
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 37ms/step - accuracy: 0.3448 - loss: 0.1362 - macro_f1: 0.1074 - weighted_f1: 0.2047 - val_accuracy: 0.4301 - val_loss: 0.1600 - val_macro_f1: 0.1428 - val_weighted_f1: 0.3176 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4804 - loss: 0.0869 - macro_f1: 0.2016 - weighted_f1: 0.3819 - val_accuracy: 0.4548 - val_loss: 0.1532 - val_macro_f1: 0.1726 - val_weighted_f1: 0.2904 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5148 - loss: 0.0732 - macro_f1: 0.2403 - weighted_f1: 0.4333 - val_accuracy: 0.4804 - val_loss: 0.1404 - val_macro_f1: 0.2085 - val_weighted_f1: 0.3560 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5415 - loss: 0.0651 - macro_f1: 0.2588 - weighted_f1: 0.4734 - val_accuracy: 0.5443 - val_loss: 0.1298 - val_macro_f1: 0.2192 - val_weighted_f1: 0.4798 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5477 - loss: 0.0638 - macro_f1: 0.2872 - weighted_f1: 0.5302 - val_accuracy: 0.4958 - val_loss: 0.1275 - val_macro_f1: 0.2590 - val_weighted_f1: 0.4793 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5535 - loss: 0.0602 - macro_f1: 0.3038 - weighted_f1: 0.5404 - val_accuracy: 0.5718 - val_loss: 0.1147 - val_macro_f1: 0.2730 - val_weighted_f1: 0.5431 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5790 - loss: 0.0540 - macro_f1: 0.3297 - weighted_f1: 0.5782 - val_accuracy: 0.5186 - val_loss: 0.1239 - val_macro_f1: 0.2676 - val_weighted_f1: 0.4902 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5774 - loss: 0.0507 - macro_f1: 0.3483 - weighted_f1: 0.5921 - val_accuracy: 0.5829 - val_loss: 0.1097 - val_macro_f1: 0.2821 - val_weighted_f1: 0.5763 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6026 - loss: 0.0500 - macro_f1: 0.3552 - weighted_f1: 0.6065 - val_accuracy: 0.5494 - val_loss: 0.1175 - val_macro_f1: 0.2958 - val_weighted_f1: 0.5490 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6028 - loss: 0.0463 - macro_f1: 0.3715 - weighted_f1: 0.6184 - val_accuracy: 0.5340 - val_loss: 0.1194 - val_macro_f1: 0.3090 - val_weighted_f1: 0.5582 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6163 - loss: 0.0441 - macro_f1: 0.3847 - weighted_f1: 0.6364 - val_accuracy: 0.5834 - val_loss: 0.1107 - val_macro_f1: 0.3048 - val_weighted_f1: 0.5952 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6233 - loss: 0.0435 - macro_f1: 0.3957 - weighted_f1: 0.6520 - val_accuracy: 0.5797 - val_loss: 0.1120 - val_macro_f1: 0.3082 - val_weighted_f1: 0.5885 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6159 - loss: 0.0457 - macro_f1: 0.3897 - weighted_f1: 0.6471 - val_accuracy: 0.5555 - val_loss: 0.1187 - val_macro_f1: 0.3120 - val_weighted_f1: 0.5599 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6395 - loss: 0.0365 - macro_f1: 0.4185 - weighted_f1: 0.6798 - val_accuracy: 0.6156 - val_loss: 0.1025 - val_macro_f1: 0.3292 - val_weighted_f1: 0.6258 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6563 - loss: 0.0337 - macro_f1: 0.4305 - weighted_f1: 0.6979 - val_accuracy: 0.6128 - val_loss: 0.1040 - val_macro_f1: 0.3312 - val_weighted_f1: 0.6299 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6583 - loss: 0.0325 - macro_f1: 0.4495 - weighted_f1: 0.7049 - val_accuracy: 0.6216 - val_loss: 0.1030 - val_macro_f1: 0.3317 - val_weighted_f1: 0.6359 - learning_rate: 1.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6686 - loss: 0.0318 - macro_f1: 0.4515 - weighted_f1: 0.7146 - val_accuracy: 0.6142 - val_loss: 0.1034 - val_macro_f1: 0.3323 - val_weighted_f1: 0.6395 - learning_rate: 1.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6711 - loss: 0.0309 - macro_f1: 0.4685 - weighted_f1: 0.7237 - val_accuracy: 0.6160 - val_loss: 0.1045 - val_macro_f1: 0.3311 - val_weighted_f1: 0.6370 - learning_rate: 1.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6713 - loss: 0.0300 - macro_f1: 0.4624 - weighted_f1: 0.7245 - val_accuracy: 0.6123 - val_loss: 0.1046 - val_macro_f1: 0.3437 - val_weighted_f1: 0.6418 - learning_rate: 1.0000e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6713 - loss: 0.0295 - macro_f1: 0.4800 - weighted_f1: 0.7332 - val_accuracy: 0.6128 - val_loss: 0.1047 - val_macro_f1: 0.3446 - val_weighted_f1: 0.6428 - learning_rate: 1.0000e-05\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6777 - loss: 0.0294 - macro_f1: 0.4808 - weighted_f1: 0.7336 - val_accuracy: 0.6212 - val_loss: 0.1043 - val_macro_f1: 0.3434 - val_weighted_f1: 0.6441 - learning_rate: 1.0000e-05\n",
      "Epoch 22/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6756 - loss: 0.0295 - macro_f1: 0.4642 - weighted_f1: 0.7288 - val_accuracy: 0.6165 - val_loss: 0.1046 - val_macro_f1: 0.3428 - val_weighted_f1: 0.6410 - learning_rate: 1.0000e-05\n",
      "Epoch 23/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6756 - loss: 0.0292 - macro_f1: 0.4663 - weighted_f1: 0.7300 - val_accuracy: 0.6151 - val_loss: 0.1049 - val_macro_f1: 0.3401 - val_weighted_f1: 0.6397 - learning_rate: 1.0000e-05\n",
      "Epoch 24/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6779 - loss: 0.0293 - macro_f1: 0.4742 - weighted_f1: 0.7323 - val_accuracy: 0.6156 - val_loss: 0.1047 - val_macro_f1: 0.3406 - val_weighted_f1: 0.6404 - learning_rate: 1.0000e-05\n",
      "Working on ResNet for LwF Now:\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step\n",
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 91ms/step - accuracy: 0.3010 - loss: 0.1430 - macro_f1: 0.0556 - weighted_f1: 0.1148 - val_accuracy: 0.2810 - val_loss: 0.1932 - val_macro_f1: 0.0955 - val_weighted_f1: 0.1715 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4353 - loss: 0.0959 - macro_f1: 0.1347 - weighted_f1: 0.2469 - val_accuracy: 0.0937 - val_loss: 0.2893 - val_macro_f1: 0.0725 - val_weighted_f1: 0.0716 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4379 - loss: 0.0981 - macro_f1: 0.1217 - weighted_f1: 0.2375 - val_accuracy: 0.4348 - val_loss: 0.1668 - val_macro_f1: 0.1371 - val_weighted_f1: 0.2418 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4731 - loss: 0.0869 - macro_f1: 0.1760 - weighted_f1: 0.3149 - val_accuracy: 0.0014 - val_loss: 74.7346 - val_macro_f1: 0.0084 - val_weighted_f1: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4493 - loss: 0.0865 - macro_f1: 0.1532 - weighted_f1: 0.2671 - val_accuracy: 0.3863 - val_loss: 0.1750 - val_macro_f1: 0.1148 - val_weighted_f1: 0.2378 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4906 - loss: 0.0797 - macro_f1: 0.1934 - weighted_f1: 0.3509 - val_accuracy: 0.4595 - val_loss: 0.1463 - val_macro_f1: 0.1781 - val_weighted_f1: 0.2926 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5018 - loss: 0.0784 - macro_f1: 0.2106 - weighted_f1: 0.3858 - val_accuracy: 0.4492 - val_loss: 0.1478 - val_macro_f1: 0.1929 - val_weighted_f1: 0.3968 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5188 - loss: 0.0695 - macro_f1: 0.2520 - weighted_f1: 0.4406 - val_accuracy: 0.2521 - val_loss: 0.2011 - val_macro_f1: 0.1093 - val_weighted_f1: 0.1576 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5097 - loss: 0.0684 - macro_f1: 0.2483 - weighted_f1: 0.4369 - val_accuracy: 0.4366 - val_loss: 0.1517 - val_macro_f1: 0.1836 - val_weighted_f1: 0.3484 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5282 - loss: 0.0673 - macro_f1: 0.2708 - weighted_f1: 0.4842 - val_accuracy: 0.4138 - val_loss: 0.1477 - val_macro_f1: 0.2298 - val_weighted_f1: 0.3951 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5481 - loss: 0.0617 - macro_f1: 0.3018 - weighted_f1: 0.5174 - val_accuracy: 0.4627 - val_loss: 0.1482 - val_macro_f1: 0.2125 - val_weighted_f1: 0.4009 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5641 - loss: 0.0574 - macro_f1: 0.2932 - weighted_f1: 0.5228 - val_accuracy: 0.5610 - val_loss: 0.1154 - val_macro_f1: 0.2800 - val_weighted_f1: 0.5386 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5820 - loss: 0.0517 - macro_f1: 0.3377 - weighted_f1: 0.5824 - val_accuracy: 0.5685 - val_loss: 0.1130 - val_macro_f1: 0.2964 - val_weighted_f1: 0.5630 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5983 - loss: 0.0485 - macro_f1: 0.3625 - weighted_f1: 0.6053 - val_accuracy: 0.5699 - val_loss: 0.1155 - val_macro_f1: 0.2942 - val_weighted_f1: 0.5589 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5886 - loss: 0.0479 - macro_f1: 0.3650 - weighted_f1: 0.6137 - val_accuracy: 0.5792 - val_loss: 0.1126 - val_macro_f1: 0.3019 - val_weighted_f1: 0.5746 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6034 - loss: 0.0455 - macro_f1: 0.3659 - weighted_f1: 0.6235 - val_accuracy: 0.5732 - val_loss: 0.1133 - val_macro_f1: 0.3010 - val_weighted_f1: 0.5825 - learning_rate: 1.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6097 - loss: 0.0445 - macro_f1: 0.3809 - weighted_f1: 0.6290 - val_accuracy: 0.5629 - val_loss: 0.1147 - val_macro_f1: 0.3093 - val_weighted_f1: 0.5816 - learning_rate: 1.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6040 - loss: 0.0434 - macro_f1: 0.3800 - weighted_f1: 0.6350 - val_accuracy: 0.5788 - val_loss: 0.1144 - val_macro_f1: 0.3071 - val_weighted_f1: 0.5849 - learning_rate: 1.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6201 - loss: 0.0432 - macro_f1: 0.3940 - weighted_f1: 0.6470 - val_accuracy: 0.5797 - val_loss: 0.1104 - val_macro_f1: 0.3076 - val_weighted_f1: 0.5823 - learning_rate: 1.0000e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6225 - loss: 0.0413 - macro_f1: 0.3931 - weighted_f1: 0.6511 - val_accuracy: 0.5843 - val_loss: 0.1118 - val_macro_f1: 0.3067 - val_weighted_f1: 0.5983 - learning_rate: 1.0000e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6300 - loss: 0.0395 - macro_f1: 0.4077 - weighted_f1: 0.6649 - val_accuracy: 0.5797 - val_loss: 0.1135 - val_macro_f1: 0.3109 - val_weighted_f1: 0.5902 - learning_rate: 1.0000e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6222 - loss: 0.0387 - macro_f1: 0.4103 - weighted_f1: 0.6667 - val_accuracy: 0.5732 - val_loss: 0.1160 - val_macro_f1: 0.3127 - val_weighted_f1: 0.5955 - learning_rate: 1.0000e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6391 - loss: 0.0373 - macro_f1: 0.4267 - weighted_f1: 0.6816 - val_accuracy: 0.5937 - val_loss: 0.1114 - val_macro_f1: 0.3206 - val_weighted_f1: 0.6049 - learning_rate: 1.0000e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6373 - loss: 0.0362 - macro_f1: 0.4366 - weighted_f1: 0.6890 - val_accuracy: 0.5615 - val_loss: 0.1281 - val_macro_f1: 0.3118 - val_weighted_f1: 0.5776 - learning_rate: 1.0000e-04\n",
      "Epoch 25/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6395 - loss: 0.0336 - macro_f1: 0.4471 - weighted_f1: 0.6940 - val_accuracy: 0.5848 - val_loss: 0.1126 - val_macro_f1: 0.3210 - val_weighted_f1: 0.6082 - learning_rate: 1.0000e-05\n",
      "Working on ViT for LwF Now:\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 115ms/step - accuracy: 0.1481 - loss: 0.1495 - macro_f1: 0.0466 - weighted_f1: 0.0758 - val_accuracy: 0.1305 - val_loss: 0.2047 - val_macro_f1: 0.0882 - val_weighted_f1: 0.0943 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.3291 - loss: 0.0923 - macro_f1: 0.1267 - weighted_f1: 0.2112 - val_accuracy: 0.4436 - val_loss: 0.1651 - val_macro_f1: 0.1023 - val_weighted_f1: 0.2587 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.4482 - loss: 0.0722 - macro_f1: 0.2052 - weighted_f1: 0.3530 - val_accuracy: 0.5210 - val_loss: 0.1421 - val_macro_f1: 0.1772 - val_weighted_f1: 0.4215 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.5252 - loss: 0.0572 - macro_f1: 0.2881 - weighted_f1: 0.4768 - val_accuracy: 0.4870 - val_loss: 0.1473 - val_macro_f1: 0.2105 - val_weighted_f1: 0.4195 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.5520 - loss: 0.0494 - macro_f1: 0.3319 - weighted_f1: 0.5381 - val_accuracy: 0.5261 - val_loss: 0.1442 - val_macro_f1: 0.2384 - val_weighted_f1: 0.5110 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.5981 - loss: 0.0404 - macro_f1: 0.3907 - weighted_f1: 0.6179 - val_accuracy: 0.4725 - val_loss: 0.1570 - val_macro_f1: 0.2088 - val_weighted_f1: 0.3612 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6147 - loss: 0.0378 - macro_f1: 0.4031 - weighted_f1: 0.6226 - val_accuracy: 0.5247 - val_loss: 0.1498 - val_macro_f1: 0.2322 - val_weighted_f1: 0.4778 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.6268 - loss: 0.0342 - macro_f1: 0.4480 - weighted_f1: 0.6691 - val_accuracy: 0.5191 - val_loss: 0.1530 - val_macro_f1: 0.2169 - val_weighted_f1: 0.4550 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.6704 - loss: 0.0270 - macro_f1: 0.4721 - weighted_f1: 0.7085 - val_accuracy: 0.5433 - val_loss: 0.1455 - val_macro_f1: 0.2547 - val_weighted_f1: 0.5398 - learning_rate: 1.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.6921 - loss: 0.0239 - macro_f1: 0.5107 - weighted_f1: 0.7496 - val_accuracy: 0.5480 - val_loss: 0.1465 - val_macro_f1: 0.2551 - val_weighted_f1: 0.5424 - learning_rate: 1.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.6942 - loss: 0.0219 - macro_f1: 0.5235 - weighted_f1: 0.7645 - val_accuracy: 0.5564 - val_loss: 0.1470 - val_macro_f1: 0.2586 - val_weighted_f1: 0.5462 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7032 - loss: 0.0209 - macro_f1: 0.5188 - weighted_f1: 0.7674 - val_accuracy: 0.5382 - val_loss: 0.1519 - val_macro_f1: 0.2610 - val_weighted_f1: 0.5352 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.7015 - loss: 0.0205 - macro_f1: 0.5296 - weighted_f1: 0.7745 - val_accuracy: 0.5545 - val_loss: 0.1525 - val_macro_f1: 0.2567 - val_weighted_f1: 0.5397 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbb7f13be50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_soft_targets_super = cnn_super_model.predict(X_train)\n",
    "\n",
    "def lwf_loss(y_true, y_pred, old_predictions, T=2):\n",
    "    task_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dist_loss = tf.keras.losses.KLDivergence()(tf.nn.softmax(old_predictions / T),\n",
    "                                               tf.nn.softmax(y_pred / T))\n",
    "    total_loss = task_loss + dist_loss\n",
    "    return total_loss\n",
    "\n",
    "print(\"Working on CNN for LwF Now:\")\n",
    "cnn_model_lwf = create_cnn_model(input_shape, num_classes_sub)\n",
    "cnn_model_lwf.compile(\n",
    "    optimizer='adam',\n",
    "    loss=lambda y_true, y_pred: lwf_loss(y_true, y_pred, old_predictions=cnn_soft_targets_super),\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "train_model(cnn_model_lwf, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)\n",
    "\n",
    "print(\"Working on ResNet for LwF Now:\")\n",
    "resnet_soft_targets_super = resnet_super_model.predict(X_train)\n",
    "resnet_model_lwf = create_resnet_model(input_shape, num_classes_sub)\n",
    "resnet_model_lwf.compile(\n",
    "    optimizer='adam',\n",
    "    loss=lambda y_true, y_pred: lwf_loss(y_true, y_pred, old_predictions=resnet_soft_targets_super),\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "train_model(resnet_model_lwf, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)\n",
    "\n",
    "print(\"Working on ViT for LwF Now:\")\n",
    "vit_soft_targets_super = vit_super_model.predict(X_train)\n",
    "vit_model_lwf = create_vit_model(input_shape, num_classes_sub)\n",
    "vit_model_lwf.compile(\n",
    "    optimizer='adam',\n",
    "    loss=lambda y_true, y_pred: lwf_loss(y_true, y_pred, old_predictions=vit_soft_targets_super),\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "train_model(vit_model_lwf, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining and Training on EwC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWC:\n",
    "    def __init__(self, model, X, y, batch_size=32, exclude_params=[]):\n",
    "        self.model = model\n",
    "        self.params = {}\n",
    "        for p in model.trainable_variables:\n",
    "            if id(p) not in exclude_params:\n",
    "                self.params[id(p)] = p.numpy()\n",
    "        self.fisher = self.compute_fisher(X, y, batch_size, exclude_params)\n",
    "\n",
    "    def compute_fisher(self, X, y, batch_size, exclude_params):\n",
    "        fisher = {}\n",
    "        num_samples = X.shape[0]\n",
    "        num_batches = int(np.ceil(num_samples / batch_size))\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            X_batch = X[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "            y_batch = y[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "            with tf.GradientTape() as tape:\n",
    "                preds = self.model(X_batch)\n",
    "                loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "            for p, g in zip(self.model.trainable_variables, grads):\n",
    "                if g is not None and id(p) not in exclude_params:\n",
    "                    param_id = id(p)\n",
    "                    if param_id not in fisher:\n",
    "                        fisher[param_id] = np.square(g.numpy())\n",
    "                    else:\n",
    "                        fisher[param_id] += np.square(g.numpy())\n",
    "        for k in fisher.keys():\n",
    "            fisher[k] /= num_batches\n",
    "        return fisher\n",
    "\n",
    "    def penalty(self, model):\n",
    "        loss = 0\n",
    "        for p in model.trainable_variables:\n",
    "            param_id = id(p)\n",
    "            if param_id in self.fisher:\n",
    "                fisher = tf.convert_to_tensor(self.fisher[param_id])\n",
    "                loss += tf.reduce_sum(fisher * tf.square(p - self.params[param_id]))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_model_for_subdiagnostic(base_model, num_classes_sub):\n",
    "    inputs = base_model.input\n",
    "    x = inputs\n",
    "    for layer in base_model.layers[1:-1]:\n",
    "        x = layer(x)\n",
    "    outputs = layers.Dense(num_classes_sub, activation='sigmoid', name='output_sub')(x)\n",
    "    new_model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 37ms/step - accuracy: 0.5679 - loss: 0.1121 - macro_f1: 0.2046 - weighted_f1: 0.4335 - val_accuracy: 0.5746 - val_loss: 0.1171 - val_macro_f1: 0.2678 - val_weighted_f1: 0.5360 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6148 - loss: 0.0629 - macro_f1: 0.3285 - weighted_f1: 0.6024 - val_accuracy: 0.5177 - val_loss: 0.1266 - val_macro_f1: 0.2672 - val_weighted_f1: 0.5130 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6330 - loss: 0.0510 - macro_f1: 0.3561 - weighted_f1: 0.6332 - val_accuracy: 0.6109 - val_loss: 0.1137 - val_macro_f1: 0.2776 - val_weighted_f1: 0.5691 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6496 - loss: 0.0440 - macro_f1: 0.3821 - weighted_f1: 0.6697 - val_accuracy: 0.5988 - val_loss: 0.1113 - val_macro_f1: 0.3051 - val_weighted_f1: 0.5855 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6560 - loss: 0.0422 - macro_f1: 0.3984 - weighted_f1: 0.6759 - val_accuracy: 0.6244 - val_loss: 0.1051 - val_macro_f1: 0.3190 - val_weighted_f1: 0.6165 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6600 - loss: 0.0389 - macro_f1: 0.4187 - weighted_f1: 0.6983 - val_accuracy: 0.5783 - val_loss: 0.1180 - val_macro_f1: 0.3206 - val_weighted_f1: 0.6010 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6630 - loss: 0.0358 - macro_f1: 0.4417 - weighted_f1: 0.7121 - val_accuracy: 0.6034 - val_loss: 0.1116 - val_macro_f1: 0.3195 - val_weighted_f1: 0.6077 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6700 - loss: 0.0328 - macro_f1: 0.4587 - weighted_f1: 0.7262 - val_accuracy: 0.6184 - val_loss: 0.1109 - val_macro_f1: 0.3235 - val_weighted_f1: 0.6194 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6811 - loss: 0.0303 - macro_f1: 0.4746 - weighted_f1: 0.7455 - val_accuracy: 0.6379 - val_loss: 0.1089 - val_macro_f1: 0.3307 - val_weighted_f1: 0.6370 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6920 - loss: 0.0279 - macro_f1: 0.4933 - weighted_f1: 0.7629 - val_accuracy: 0.6095 - val_loss: 0.1155 - val_macro_f1: 0.3309 - val_weighted_f1: 0.6290 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7132 - loss: 0.0232 - macro_f1: 0.5136 - weighted_f1: 0.7929 - val_accuracy: 0.6286 - val_loss: 0.1099 - val_macro_f1: 0.3411 - val_weighted_f1: 0.6435 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7409 - loss: 0.0198 - macro_f1: 0.5396 - weighted_f1: 0.8186 - val_accuracy: 0.6277 - val_loss: 0.1114 - val_macro_f1: 0.3446 - val_weighted_f1: 0.6472 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7307 - loss: 0.0193 - macro_f1: 0.5408 - weighted_f1: 0.8189 - val_accuracy: 0.6277 - val_loss: 0.1132 - val_macro_f1: 0.3359 - val_weighted_f1: 0.6446 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7376 - loss: 0.0180 - macro_f1: 0.5523 - weighted_f1: 0.8274 - val_accuracy: 0.6263 - val_loss: 0.1143 - val_macro_f1: 0.3377 - val_weighted_f1: 0.6434 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7455 - loss: 0.0173 - macro_f1: 0.5614 - weighted_f1: 0.8325 - val_accuracy: 0.6212 - val_loss: 0.1160 - val_macro_f1: 0.3371 - val_weighted_f1: 0.6416 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb2c4312f40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ewc = 1000\n",
    "cnn_sub_model = modify_model_for_subdiagnostic(cnn_super_model, num_classes_sub)\n",
    "exclude_params_cnn = [id(w) for w in cnn_sub_model.layers[-1].trainable_weights]\n",
    "ewc_cnn = EWC(cnn_super_model, X_train, y_train_super, exclude_params=exclude_params_cnn)\n",
    "\n",
    "def ewc_loss_cnn(y_true, y_pred):\n",
    "    task_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    ewc_penalty = ewc_cnn.penalty(cnn_sub_model)\n",
    "    total_loss = task_loss + (lambda_ewc / 2) * ewc_penalty\n",
    "    return total_loss\n",
    "\n",
    "cnn_sub_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=ewc_loss_cnn,\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "\n",
    "train_model(cnn_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_model_for_subdiagnostic_resnet(base_model, num_classes_sub):\n",
    "    x = base_model.layers[-2].output\n",
    "    outputs = layers.Dense(num_classes_sub, activation='sigmoid', name='output_sub')(x)\n",
    "    new_model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 90ms/step - accuracy: 0.4394 - loss: 0.1169 - macro_f1: 0.1501 - weighted_f1: 0.3199 - val_accuracy: 0.3164 - val_loss: 0.1830 - val_macro_f1: 0.1394 - val_weighted_f1: 0.2305 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5250 - loss: 0.0829 - macro_f1: 0.2184 - weighted_f1: 0.4229 - val_accuracy: 0.2968 - val_loss: 0.2285 - val_macro_f1: 0.1674 - val_weighted_f1: 0.3298 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5465 - loss: 0.0694 - macro_f1: 0.2528 - weighted_f1: 0.4821 - val_accuracy: 0.4082 - val_loss: 0.1748 - val_macro_f1: 0.1672 - val_weighted_f1: 0.3434 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5612 - loss: 0.0662 - macro_f1: 0.2729 - weighted_f1: 0.5182 - val_accuracy: 0.4585 - val_loss: 0.1529 - val_macro_f1: 0.1565 - val_weighted_f1: 0.3416 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5601 - loss: 0.0674 - macro_f1: 0.2811 - weighted_f1: 0.5250 - val_accuracy: 0.5112 - val_loss: 0.1324 - val_macro_f1: 0.2227 - val_weighted_f1: 0.4705 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5854 - loss: 0.0603 - macro_f1: 0.3045 - weighted_f1: 0.5579 - val_accuracy: 0.3308 - val_loss: 0.2089 - val_macro_f1: 0.1882 - val_weighted_f1: 0.3189 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5856 - loss: 0.0597 - macro_f1: 0.3189 - weighted_f1: 0.5667 - val_accuracy: 0.4478 - val_loss: 0.1661 - val_macro_f1: 0.2096 - val_weighted_f1: 0.4206 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5489 - loss: 0.0721 - macro_f1: 0.2948 - weighted_f1: 0.5274 - val_accuracy: 0.5354 - val_loss: 0.1283 - val_macro_f1: 0.2772 - val_weighted_f1: 0.4893 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5838 - loss: 0.0566 - macro_f1: 0.3197 - weighted_f1: 0.5768 - val_accuracy: 0.5755 - val_loss: 0.1193 - val_macro_f1: 0.3051 - val_weighted_f1: 0.5668 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6028 - loss: 0.0499 - macro_f1: 0.3539 - weighted_f1: 0.6126 - val_accuracy: 0.5377 - val_loss: 0.1231 - val_macro_f1: 0.2989 - val_weighted_f1: 0.5430 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6101 - loss: 0.0487 - macro_f1: 0.3493 - weighted_f1: 0.6136 - val_accuracy: 0.5937 - val_loss: 0.1141 - val_macro_f1: 0.3144 - val_weighted_f1: 0.5961 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6163 - loss: 0.0459 - macro_f1: 0.3801 - weighted_f1: 0.6448 - val_accuracy: 0.6048 - val_loss: 0.1160 - val_macro_f1: 0.2969 - val_weighted_f1: 0.5874 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6355 - loss: 0.0427 - macro_f1: 0.3860 - weighted_f1: 0.6531 - val_accuracy: 0.5871 - val_loss: 0.1174 - val_macro_f1: 0.2904 - val_weighted_f1: 0.5824 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6371 - loss: 0.0432 - macro_f1: 0.3842 - weighted_f1: 0.6547 - val_accuracy: 0.5056 - val_loss: 0.1354 - val_macro_f1: 0.2558 - val_weighted_f1: 0.5003 - learning_rate: 0.0010\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6053 - loss: 0.0482 - macro_f1: 0.3702 - weighted_f1: 0.6220 - val_accuracy: 0.5643 - val_loss: 0.1164 - val_macro_f1: 0.3108 - val_weighted_f1: 0.5893 - learning_rate: 0.0010\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6357 - loss: 0.0394 - macro_f1: 0.3992 - weighted_f1: 0.6684 - val_accuracy: 0.5666 - val_loss: 0.1208 - val_macro_f1: 0.3127 - val_weighted_f1: 0.5825 - learning_rate: 0.0010\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6472 - loss: 0.0332 - macro_f1: 0.4484 - weighted_f1: 0.7037 - val_accuracy: 0.6202 - val_loss: 0.1065 - val_macro_f1: 0.3357 - val_weighted_f1: 0.6416 - learning_rate: 1.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6744 - loss: 0.0306 - macro_f1: 0.4717 - weighted_f1: 0.7326 - val_accuracy: 0.6193 - val_loss: 0.1068 - val_macro_f1: 0.3375 - val_weighted_f1: 0.6455 - learning_rate: 1.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6768 - loss: 0.0291 - macro_f1: 0.4789 - weighted_f1: 0.7439 - val_accuracy: 0.6100 - val_loss: 0.1109 - val_macro_f1: 0.3399 - val_weighted_f1: 0.6421 - learning_rate: 1.0000e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6925 - loss: 0.0276 - macro_f1: 0.4904 - weighted_f1: 0.7550 - val_accuracy: 0.6156 - val_loss: 0.1103 - val_macro_f1: 0.3355 - val_weighted_f1: 0.6431 - learning_rate: 1.0000e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6870 - loss: 0.0263 - macro_f1: 0.4906 - weighted_f1: 0.7613 - val_accuracy: 0.6118 - val_loss: 0.1122 - val_macro_f1: 0.3381 - val_weighted_f1: 0.6467 - learning_rate: 1.0000e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6935 - loss: 0.0253 - macro_f1: 0.4968 - weighted_f1: 0.7694 - val_accuracy: 0.6025 - val_loss: 0.1159 - val_macro_f1: 0.3433 - val_weighted_f1: 0.6478 - learning_rate: 1.0000e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6988 - loss: 0.0237 - macro_f1: 0.5147 - weighted_f1: 0.7771 - val_accuracy: 0.6002 - val_loss: 0.1167 - val_macro_f1: 0.3439 - val_weighted_f1: 0.6455 - learning_rate: 1.0000e-05\n",
      "Epoch 24/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7045 - loss: 0.0230 - macro_f1: 0.5187 - weighted_f1: 0.7799 - val_accuracy: 0.6025 - val_loss: 0.1169 - val_macro_f1: 0.3442 - val_weighted_f1: 0.6457 - learning_rate: 1.0000e-05\n",
      "Epoch 25/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7025 - loss: 0.0234 - macro_f1: 0.5118 - weighted_f1: 0.7804 - val_accuracy: 0.6021 - val_loss: 0.1181 - val_macro_f1: 0.3447 - val_weighted_f1: 0.6446 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fbb77744400>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes_sub = y_train_sub.shape[1]\n",
    "resnet_sub_model = modify_model_for_subdiagnostic_resnet(resnet_super_model, num_classes_sub)\n",
    "exclude_params_resnet = [w.name for w in resnet_sub_model.layers[-1].trainable_weights]\n",
    "def ewc_loss_resnet(y_true, y_pred):\n",
    "    task_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    ewc_penalty = ewc_resnet.penalty(resnet_sub_model)\n",
    "    total_loss = task_loss + (lambda_ewc / 2) * ewc_penalty\n",
    "    return total_loss\n",
    "\n",
    "resnet_sub_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=ewc_loss_resnet,\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "\n",
    "train_model(resnet_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_model_for_subdiagnostic_vit(base_model, num_classes_sub):\n",
    "    # Get the output of the layer before the last (excluding the superdiagnostic output layer)\n",
    "    x = base_model.layers[-2].output\n",
    "    # Add new output layer for subdiagnostic task\n",
    "    outputs = tf.keras.layers.Dense(num_classes_sub, activation='sigmoid', name='output_sub')(x)\n",
    "    # Create new model\n",
    "    new_model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 113ms/step - accuracy: 0.4333 - loss: 0.1121 - macro_f1: 0.1332 - weighted_f1: 0.2994 - val_accuracy: 0.5103 - val_loss: 0.1520 - val_macro_f1: 0.1501 - val_weighted_f1: 0.3355 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.5326 - loss: 0.0738 - macro_f1: 0.2166 - weighted_f1: 0.4266 - val_accuracy: 0.5666 - val_loss: 0.1283 - val_macro_f1: 0.2160 - val_weighted_f1: 0.5024 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.5640 - loss: 0.0587 - macro_f1: 0.2874 - weighted_f1: 0.5220 - val_accuracy: 0.5363 - val_loss: 0.1327 - val_macro_f1: 0.2443 - val_weighted_f1: 0.5239 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.5951 - loss: 0.0485 - macro_f1: 0.3420 - weighted_f1: 0.5785 - val_accuracy: 0.5331 - val_loss: 0.1390 - val_macro_f1: 0.2485 - val_weighted_f1: 0.5063 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6145 - loss: 0.0408 - macro_f1: 0.3880 - weighted_f1: 0.6194 - val_accuracy: 0.5485 - val_loss: 0.1342 - val_macro_f1: 0.2393 - val_weighted_f1: 0.5343 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6460 - loss: 0.0343 - macro_f1: 0.4389 - weighted_f1: 0.6886 - val_accuracy: 0.5270 - val_loss: 0.1430 - val_macro_f1: 0.2309 - val_weighted_f1: 0.4853 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6652 - loss: 0.0301 - macro_f1: 0.4668 - weighted_f1: 0.7111 - val_accuracy: 0.5610 - val_loss: 0.1397 - val_macro_f1: 0.2610 - val_weighted_f1: 0.5411 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7091 - loss: 0.0229 - macro_f1: 0.5156 - weighted_f1: 0.7668 - val_accuracy: 0.5811 - val_loss: 0.1428 - val_macro_f1: 0.2723 - val_weighted_f1: 0.5684 - learning_rate: 1.0000e-04\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7201 - loss: 0.0200 - macro_f1: 0.5326 - weighted_f1: 0.7926 - val_accuracy: 0.5876 - val_loss: 0.1459 - val_macro_f1: 0.2732 - val_weighted_f1: 0.5791 - learning_rate: 1.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7296 - loss: 0.0185 - macro_f1: 0.5437 - weighted_f1: 0.8020 - val_accuracy: 0.5806 - val_loss: 0.1468 - val_macro_f1: 0.2719 - val_weighted_f1: 0.5749 - learning_rate: 1.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7288 - loss: 0.0179 - macro_f1: 0.5476 - weighted_f1: 0.8085 - val_accuracy: 0.5848 - val_loss: 0.1487 - val_macro_f1: 0.2787 - val_weighted_f1: 0.5798 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7336 - loss: 0.0169 - macro_f1: 0.5495 - weighted_f1: 0.8145 - val_accuracy: 0.5890 - val_loss: 0.1513 - val_macro_f1: 0.2764 - val_weighted_f1: 0.5799 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb2547aa670>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify ViT model for subdiagnostic task\n",
    "num_classes_sub = y_train_sub.shape[1]\n",
    "vit_sub_model = modify_model_for_subdiagnostic_vit(vit_super_model, num_classes_sub)\n",
    "\n",
    "# Exclude the new output layer's parameters from EWC or SI calculations\n",
    "exclude_params_vit = [w.name for w in vit_sub_model.layers[-1].trainable_weights]\n",
    "\n",
    "def ewc_loss_vit(y_true, y_pred):\n",
    "    task_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    ewc_penalty = ewc_vit.penalty(vit_sub_model)\n",
    "    total_loss = task_loss + (lambda_ewc / 2) * ewc_penalty\n",
    "    return total_loss\n",
    "\n",
    "vit_sub_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=ewc_loss_vit,\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "\n",
    "train_model(vit_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining and Training on SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SI:\n",
    "    def __init__(self, prev_model, damping_factor=0.1, exclude_params=[]):\n",
    "        self.prev_params = {}\n",
    "        self.omega = {}\n",
    "        self.damping_factor = damping_factor\n",
    "        self.exclude_params = exclude_params\n",
    "\n",
    "        self.delta_params = {}\n",
    "\n",
    "        # Store parameters from the previous model (superdiagnostic task)\n",
    "        for var in prev_model.trainable_variables:\n",
    "            if var.name not in self.exclude_params:\n",
    "                self.prev_params[var.name] = var.numpy().copy()\n",
    "                self.omega[var.name] = np.zeros_like(var.numpy())\n",
    "                self.delta_params[var.name] = np.zeros_like(var.numpy())\n",
    "\n",
    "    def accumulate_importance(self, model, grads):\n",
    "        for var, grad in zip(model.trainable_variables, grads):\n",
    "            if grad is not None and var.name in self.prev_params:\n",
    "                if var.shape == self.prev_params[var.name].shape:\n",
    "                    delta_theta = var.numpy() - self.prev_params[var.name]\n",
    "                    self.delta_params[var.name] += delta_theta\n",
    "                    # Update omega with absolute value to prevent negative importance\n",
    "                    self.omega[var.name] += np.abs(grad.numpy() * delta_theta)\n",
    "                else:\n",
    "                    # Skip variables with mismatched shapes\n",
    "                    pass\n",
    "\n",
    "    def update_omega(self):\n",
    "        # Normalize omega after training\n",
    "        epsilon = 1e-8  # Small value to prevent division by zero\n",
    "        for var_name in self.omega.keys():\n",
    "            delta_param = self.delta_params[var_name]\n",
    "            denom = np.square(delta_param) + self.damping_factor + epsilon\n",
    "            self.omega[var_name] = np.divide(self.omega[var_name], denom)\n",
    "            # Ensure omega is non-negative\n",
    "            self.omega[var_name] = np.abs(self.omega[var_name])\n",
    "            # Reset delta_params for the next task\n",
    "            self.delta_params[var_name] = np.zeros_like(delta_param)\n",
    "\n",
    "    def penalty(self, model):\n",
    "        loss = 0\n",
    "        for var in model.trainable_variables:\n",
    "            if var.name in self.prev_params:\n",
    "                prev_param = self.prev_params[var.name]\n",
    "                if var.shape == prev_param.shape:\n",
    "                    omega = tf.convert_to_tensor(self.omega[var.name], dtype=var.dtype)\n",
    "                    prev_param = tf.convert_to_tensor(prev_param, dtype=var.dtype)\n",
    "                    # Ensure omega is non-negative\n",
    "                    loss += tf.reduce_sum(omega * tf.square(var - prev_param))\n",
    "                else:\n",
    "                    # Skip variables with mismatched shapes\n",
    "                    pass\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_sub = y_train_sub.shape[1]\n",
    "cnn_sub_model = modify_model_for_subdiagnostic(cnn_super_model, num_classes_sub)\n",
    "exclude_params_cnn = [w.name for w in cnn_sub_model.layers[-1].trainable_weights]\n",
    "si_cnn = SI(cnn_super_model, exclude_params=exclude_params_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/266 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Time: 45.29s, Loss: 0.1025, Macro F1: 0.3055, Val Loss: 0.1024, Val Macro F1: 0.3124\n",
      "\n",
      "CNN Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Time: 44.16s, Loss: 0.0770, Macro F1: 0.3730, Val Loss: 0.1024, Val Macro F1: 0.3233\n",
      "\n",
      "CNN Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Time: 43.35s, Loss: 0.0686, Macro F1: 0.4091, Val Loss: 0.1055, Val Macro F1: 0.3262\n",
      "\n",
      "CNN Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Time: 43.37s, Loss: 0.0605, Macro F1: 0.4425, Val Loss: 0.1109, Val Macro F1: 0.3247\n",
      "\n",
      "CNN Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Time: 42.83s, Loss: 0.0524, Macro F1: 0.4803, Val Loss: 0.1174, Val Macro F1: 0.3372\n",
      "\n",
      "CNN Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Time: 42.62s, Loss: 0.0442, Macro F1: 0.5216, Val Loss: 0.1284, Val Macro F1: 0.3261\n",
      "\n",
      "CNN Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Time: 44.37s, Loss: 0.0372, Macro F1: 0.5504, Val Loss: 0.1409, Val Macro F1: 0.3155\n",
      "\n",
      "CNN Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Time: 43.53s, Loss: 0.0311, Macro F1: 0.5802, Val Loss: 0.1576, Val Macro F1: 0.3137\n",
      "\n",
      "CNN Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Time: 44.57s, Loss: 0.0265, Macro F1: 0.5965, Val Loss: 0.1719, Val Macro F1: 0.3315\n",
      "\n",
      "CNN Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Time: 44.70s, Loss: 0.0244, Macro F1: 0.6056, Val Loss: 0.1836, Val Macro F1: 0.3153\n",
      "\n",
      "CNN Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Time: 44.02s, Loss: 0.0225, Macro F1: 0.6163, Val Loss: 0.1845, Val Macro F1: 0.3157\n",
      "\n",
      "CNN Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Time: 44.42s, Loss: 0.0186, Macro F1: 0.6331, Val Loss: 0.2024, Val Macro F1: 0.3231\n",
      "\n",
      "CNN Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Time: 42.91s, Loss: 0.0158, Macro F1: 0.6415, Val Loss: 0.2137, Val Macro F1: 0.3103\n",
      "\n",
      "CNN Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Time: 42.68s, Loss: 0.0134, Macro F1: 0.6534, Val Loss: 0.2315, Val Macro F1: 0.3162\n",
      "\n",
      "CNN Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Time: 42.31s, Loss: 0.0119, Macro F1: 0.6575, Val Loss: 0.2281, Val Macro F1: 0.3393\n",
      "\n",
      "CNN Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Time: 44.08s, Loss: 0.0112, Macro F1: 0.6612, Val Loss: 0.2283, Val Macro F1: 0.3305\n",
      "\n",
      "CNN Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Time: 44.49s, Loss: 0.0100, Macro F1: 0.6659, Val Loss: 0.2254, Val Macro F1: 0.3274\n",
      "\n",
      "CNN Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Time: 43.18s, Loss: 0.0086, Macro F1: 0.6672, Val Loss: 0.2291, Val Macro F1: 0.3200\n",
      "\n",
      "CNN Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Time: 44.13s, Loss: 0.0076, Macro F1: 0.6717, Val Loss: 0.2433, Val Macro F1: 0.3177\n",
      "\n",
      "CNN Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Time: 44.14s, Loss: 0.0074, Macro F1: 0.6714, Val Loss: 0.2498, Val Macro F1: 0.3243\n",
      "\n",
      "CNN Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Time: 44.65s, Loss: 0.0077, Macro F1: 0.6727, Val Loss: 0.2558, Val Macro F1: 0.3141\n",
      "\n",
      "CNN Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Time: 43.41s, Loss: 0.0076, Macro F1: 0.6695, Val Loss: 0.2673, Val Macro F1: 0.3185\n",
      "\n",
      "CNN Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Time: 43.88s, Loss: 0.0067, Macro F1: 0.6720, Val Loss: 0.2693, Val Macro F1: 0.3285\n",
      "\n",
      "CNN Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Time: 43.85s, Loss: 0.0060, Macro F1: 0.6758, Val Loss: 0.2712, Val Macro F1: 0.3235\n",
      "\n",
      "CNN Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Time: 43.76s, Loss: 0.0052, Macro F1: 0.6784, Val Loss: 0.2743, Val Macro F1: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "lambda_si = 1.0  # Adjust as needed\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_macro_f1 = tf.keras.metrics.Mean(name='train_macro_f1')\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_macro_f1 = tf.keras.metrics.Mean(name='val_macro_f1')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(f'\\nCNN Epoch {epoch+1}/{epochs}')\n",
    "    train_macro_f1.reset_state()\n",
    "    train_loss.reset_state()\n",
    "\n",
    "    num_batches = len(X_train) // batch_size\n",
    "    progress_bar = tqdm(range(num_batches), desc='Training', leave=False)\n",
    "\n",
    "    for step in progress_bar:\n",
    "        X_batch = X_train[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_train_sub[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = cnn_sub_model(X_batch, training=True)\n",
    "            task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "            si_penalty = si_cnn.penalty(cnn_sub_model)\n",
    "            total_loss = task_loss + (lambda_si / 2) * si_penalty\n",
    "\n",
    "        grads = tape.gradient(total_loss, cnn_sub_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, cnn_sub_model.trainable_variables))\n",
    "        si_cnn.accumulate_importance(cnn_sub_model, grads)\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        train_macro_f1.update_state(batch_macro_f1)\n",
    "        train_loss.update_state(total_loss)\n",
    "\n",
    "        progress_bar.set_postfix({'loss': train_loss.result().numpy(), 'macro_f1': train_macro_f1.result().numpy()})\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    # Validation\n",
    "    val_macro_f1.reset_state()\n",
    "    val_loss.reset_state()\n",
    "    val_batches = len(X_val) // batch_size\n",
    "    val_progress_bar = tqdm(range(val_batches), desc='Validation', leave=False)\n",
    "    for step in val_progress_bar:\n",
    "        X_batch = X_val[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_val_sub[step*batch_size:(step+1)*batch_size]\n",
    "        preds = cnn_sub_model(X_batch, training=False)\n",
    "        task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "        total_loss = task_loss\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        val_macro_f1.update_state(batch_macro_f1)\n",
    "        val_loss.update_state(total_loss)\n",
    "\n",
    "        val_progress_bar.set_postfix({'val_loss': val_loss.result().numpy(), 'val_macro_f1': val_macro_f1.result().numpy()})\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, '\n",
    "          f'Time: {epoch_time:.2f}s, '\n",
    "          f'Loss: {train_loss.result():.4f}, '\n",
    "          f'Macro F1: {train_macro_f1.result():.4f}, '\n",
    "          f'Val Loss: {val_loss.result():.4f}, '\n",
    "          f'Val Macro F1: {val_macro_f1.result():.4f}')\n",
    "\n",
    "# After training, update omega\n",
    "si_cnn.update_omega()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_sub_model = modify_model_for_subdiagnostic_resnet(resnet_super_model, num_classes_sub)\n",
    "exclude_params_resnet = [w.name for w in resnet_sub_model.layers[-1].trainable_weights]\n",
    "si_resnet = SI(resnet_sub_model, exclude_params=exclude_params_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ResNet Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/266 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Time: 283.25s, Loss: 4.3105, Macro F1: 0.2858, Val Loss: 0.1093, Val Macro F1: 0.2856\n",
      "\n",
      "ResNet Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Time: 278.60s, Loss: 0.0813, Macro F1: 0.3610, Val Loss: 0.1118, Val Macro F1: 0.2841\n",
      "\n",
      "ResNet Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Time: 270.54s, Loss: 0.0739, Macro F1: 0.3958, Val Loss: 0.1174, Val Macro F1: 0.2779\n",
      "\n",
      "ResNet Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Time: 273.52s, Loss: 0.0670, Macro F1: 0.4308, Val Loss: 0.1266, Val Macro F1: 0.2795\n",
      "\n",
      "ResNet Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Time: 279.14s, Loss: 0.0598, Macro F1: 0.4684, Val Loss: 0.1411, Val Macro F1: 0.2667\n",
      "\n",
      "ResNet Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Time: 278.15s, Loss: 0.0522, Macro F1: 0.4969, Val Loss: 0.1623, Val Macro F1: 0.2815\n",
      "\n",
      "ResNet Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Time: 275.27s, Loss: 0.0481, Macro F1: 0.5152, Val Loss: 0.1821, Val Macro F1: 0.2813\n",
      "\n",
      "ResNet Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Time: 278.12s, Loss: 0.0450, Macro F1: 0.5254, Val Loss: 0.1820, Val Macro F1: 0.2791\n",
      "\n",
      "ResNet Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Time: 281.70s, Loss: 0.0396, Macro F1: 0.5518, Val Loss: 0.1871, Val Macro F1: 0.2870\n",
      "\n",
      "ResNet Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Time: 282.47s, Loss: 0.0361, Macro F1: 0.5648, Val Loss: 0.1907, Val Macro F1: 0.2967\n",
      "\n",
      "ResNet Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Time: 274.01s, Loss: 0.0314, Macro F1: 0.5818, Val Loss: 0.1931, Val Macro F1: 0.2920\n",
      "\n",
      "ResNet Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Time: 273.64s, Loss: 0.0272, Macro F1: 0.5979, Val Loss: 0.2154, Val Macro F1: 0.2910\n",
      "\n",
      "ResNet Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Time: 276.99s, Loss: 0.0243, Macro F1: 0.6129, Val Loss: 0.2171, Val Macro F1: 0.2870\n",
      "\n",
      "ResNet Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Time: 282.88s, Loss: 0.0208, Macro F1: 0.6255, Val Loss: 0.2296, Val Macro F1: 0.2685\n",
      "\n",
      "ResNet Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Time: 283.31s, Loss: 0.0178, Macro F1: 0.6342, Val Loss: 0.2359, Val Macro F1: 0.2783\n",
      "\n",
      "ResNet Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Time: 284.08s, Loss: 0.0157, Macro F1: 0.6394, Val Loss: 0.2501, Val Macro F1: 0.2836\n",
      "\n",
      "ResNet Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Time: 282.36s, Loss: 0.0142, Macro F1: 0.6500, Val Loss: 0.2525, Val Macro F1: 0.2992\n",
      "\n",
      "ResNet Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Time: 282.05s, Loss: 0.0122, Macro F1: 0.6554, Val Loss: 0.2525, Val Macro F1: 0.2999\n",
      "\n",
      "ResNet Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Time: 276.58s, Loss: 0.0119, Macro F1: 0.6537, Val Loss: 0.2505, Val Macro F1: 0.3067\n",
      "\n",
      "ResNet Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Time: 276.24s, Loss: 0.0103, Macro F1: 0.6607, Val Loss: 0.2809, Val Macro F1: 0.3029\n",
      "\n",
      "ResNet Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Time: 279.39s, Loss: 0.0094, Macro F1: 0.6638, Val Loss: 0.2875, Val Macro F1: 0.3005\n",
      "\n",
      "ResNet Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Time: 280.00s, Loss: 0.0090, Macro F1: 0.6645, Val Loss: 0.2935, Val Macro F1: 0.3106\n",
      "\n",
      "ResNet Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Time: 280.90s, Loss: 0.0083, Macro F1: 0.6672, Val Loss: 0.2733, Val Macro F1: 0.3048\n",
      "\n",
      "ResNet Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Time: 280.47s, Loss: 0.0075, Macro F1: 0.6715, Val Loss: 0.3031, Val Macro F1: 0.2989\n",
      "\n",
      "ResNet Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Time: 283.19s, Loss: 0.0072, Macro F1: 0.6721, Val Loss: 0.3232, Val Macro F1: 0.2863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "lambda_si = 1.0  # Adjust as needed\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_macro_f1 = tf.keras.metrics.Mean(name='train_macro_f1')\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_macro_f1 = tf.keras.metrics.Mean(name='val_macro_f1')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(f'\\nResNet Epoch {epoch+1}/{epochs}')\n",
    "    train_macro_f1.reset_state()\n",
    "    train_loss.reset_state()\n",
    "\n",
    "    num_batches = len(X_train) // batch_size\n",
    "    progress_bar = tqdm(range(num_batches), desc='Training', leave=False)\n",
    "\n",
    "    for step in progress_bar:\n",
    "        X_batch = X_train[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_train_sub[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = resnet_sub_model(X_batch, training=True)\n",
    "            task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "            si_penalty = si_resnet.penalty(resnet_sub_model)\n",
    "            total_loss = task_loss + (lambda_si / 2) * si_penalty\n",
    "\n",
    "        grads = tape.gradient(total_loss, resnet_sub_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, resnet_sub_model.trainable_variables))\n",
    "        si_resnet.accumulate_importance(resnet_sub_model, grads)\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        train_macro_f1.update_state(batch_macro_f1)\n",
    "        train_loss.update_state(total_loss)\n",
    "\n",
    "        progress_bar.set_postfix({'loss': train_loss.result().numpy(), 'macro_f1': train_macro_f1.result().numpy()})\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    # Validation\n",
    "    val_macro_f1.reset_state()\n",
    "    val_loss.reset_state()\n",
    "    val_batches = len(X_val) // batch_size\n",
    "    val_progress_bar = tqdm(range(val_batches), desc='Validation', leave=False)\n",
    "    for step in val_progress_bar:\n",
    "        X_batch = X_val[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_val_sub[step*batch_size:(step+1)*batch_size]\n",
    "        preds = resnet_sub_model(X_batch, training=False)\n",
    "        task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "        total_loss = task_loss\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        val_macro_f1.update_state(batch_macro_f1)\n",
    "        val_loss.update_state(total_loss)\n",
    "\n",
    "        val_progress_bar.set_postfix({'val_loss': val_loss.result().numpy(), 'val_macro_f1': val_macro_f1.result().numpy()})\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, '\n",
    "          f'Time: {epoch_time:.2f}s, '\n",
    "          f'Loss: {train_loss.result():.4f}, '\n",
    "          f'Macro F1: {train_macro_f1.result():.4f}, '\n",
    "          f'Val Loss: {val_loss.result():.4f}, '\n",
    "          f'Val Macro F1: {val_macro_f1.result():.4f}')\n",
    "\n",
    "# After training, update omega\n",
    "si_resnet.update_omega()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_sub_model = modify_model_for_subdiagnostic_vit(vit_super_model, num_classes_sub)\n",
    "exclude_params_vit = [w.name for w in vit_sub_model.layers[-1].trainable_weights]\n",
    "si_vit = SI(vit_super_model, exclude_params=exclude_params_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ViT Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 26/266 [00:34<05:23,  1.35s/it, loss=376, macro_f1=0.112]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Time: 341.11s, Loss: 2375.8347, Macro F1: 0.2380, Val Loss: 0.1110, Val Macro F1: 0.2482\n",
      "\n",
      "ViT Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Time: 349.26s, Loss: 1198.9891, Macro F1: 0.2857, Val Loss: 0.1145, Val Macro F1: 0.2572\n",
      "\n",
      "ViT Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Time: 342.75s, Loss: 34.4861, Macro F1: 0.3366, Val Loss: 0.1232, Val Macro F1: 0.2580\n",
      "\n",
      "ViT Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Time: 341.61s, Loss: 0.0766, Macro F1: 0.3937, Val Loss: 0.1315, Val Macro F1: 0.2636\n",
      "\n",
      "ViT Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Time: 344.07s, Loss: 0.0682, Macro F1: 0.4422, Val Loss: 0.1394, Val Macro F1: 0.2533\n",
      "\n",
      "ViT Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Time: 339.96s, Loss: 0.0604, Macro F1: 0.4810, Val Loss: 0.1511, Val Macro F1: 0.2336\n",
      "\n",
      "ViT Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Time: 344.08s, Loss: 0.0541, Macro F1: 0.5103, Val Loss: 0.1601, Val Macro F1: 0.2417\n",
      "\n",
      "ViT Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Time: 350.38s, Loss: 0.0480, Macro F1: 0.5356, Val Loss: 0.1680, Val Macro F1: 0.2421\n",
      "\n",
      "ViT Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Time: 343.95s, Loss: 0.0438, Macro F1: 0.5576, Val Loss: 0.1765, Val Macro F1: 0.2426\n",
      "\n",
      "ViT Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Time: 346.55s, Loss: 0.0393, Macro F1: 0.5702, Val Loss: 0.1843, Val Macro F1: 0.2438\n",
      "\n",
      "ViT Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Time: 345.75s, Loss: 0.0364, Macro F1: 0.5861, Val Loss: 0.1903, Val Macro F1: 0.2520\n",
      "\n",
      "ViT Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Time: 346.57s, Loss: 0.0336, Macro F1: 0.5943, Val Loss: 0.1981, Val Macro F1: 0.2569\n",
      "\n",
      "ViT Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Time: 350.78s, Loss: 0.0308, Macro F1: 0.6055, Val Loss: 0.2089, Val Macro F1: 0.2382\n",
      "\n",
      "ViT Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Time: 345.07s, Loss: 0.0289, Macro F1: 0.6132, Val Loss: 0.2052, Val Macro F1: 0.2475\n",
      "\n",
      "ViT Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Time: 350.75s, Loss: 0.0271, Macro F1: 0.6166, Val Loss: 0.2174, Val Macro F1: 0.2384\n",
      "\n",
      "ViT Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Time: 348.36s, Loss: 0.0243, Macro F1: 0.6269, Val Loss: 0.2185, Val Macro F1: 0.2546\n",
      "\n",
      "ViT Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Time: 346.36s, Loss: 0.0232, Macro F1: 0.6309, Val Loss: 0.2205, Val Macro F1: 0.2470\n",
      "\n",
      "ViT Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Time: 340.19s, Loss: 0.0221, Macro F1: 0.6335, Val Loss: 0.2221, Val Macro F1: 0.2416\n",
      "\n",
      "ViT Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Time: 351.44s, Loss: 0.0207, Macro F1: 0.6395, Val Loss: 0.2284, Val Macro F1: 0.2415\n",
      "\n",
      "ViT Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Time: 348.88s, Loss: 0.0196, Macro F1: 0.6414, Val Loss: 0.2295, Val Macro F1: 0.2570\n",
      "\n",
      "ViT Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Time: 351.37s, Loss: 0.0185, Macro F1: 0.6427, Val Loss: 0.2325, Val Macro F1: 0.2639\n",
      "\n",
      "ViT Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Time: 350.20s, Loss: 0.0182, Macro F1: 0.6437, Val Loss: 0.2388, Val Macro F1: 0.2542\n",
      "\n",
      "ViT Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Time: 347.66s, Loss: 0.0164, Macro F1: 0.6499, Val Loss: 0.2449, Val Macro F1: 0.2620\n",
      "\n",
      "ViT Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Time: 347.04s, Loss: 0.0157, Macro F1: 0.6521, Val Loss: 0.2529, Val Macro F1: 0.2696\n",
      "\n",
      "ViT Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Time: 349.71s, Loss: 0.0151, Macro F1: 0.6534, Val Loss: 0.2481, Val Macro F1: 0.2589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "lambda_si = 1\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_macro_f1 = tf.keras.metrics.Mean(name='train_macro_f1')\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_macro_f1 = tf.keras.metrics.Mean(name='val_macro_f1')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(f'\\nViT Epoch {epoch+1}/{epochs}')\n",
    "    train_macro_f1.reset_state()\n",
    "    train_loss.reset_state()\n",
    "\n",
    "    num_batches = len(X_train) // batch_size\n",
    "    progress_bar = tqdm(range(num_batches), desc='Training', leave=False)\n",
    "\n",
    "    for step in progress_bar:\n",
    "        X_batch = X_train[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_train_sub[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = vit_sub_model(X_batch, training=True)\n",
    "            task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "            si_penalty = si_vit.penalty(vit_sub_model)\n",
    "            total_loss = task_loss + (lambda_si / 2) * si_penalty\n",
    "\n",
    "        # Check for NaN in total_loss\n",
    "        if tf.math.is_nan(total_loss):\n",
    "            print(f\"NaN detected in total_loss at epoch {epoch+1}, step {step+1}\")\n",
    "            break\n",
    "\n",
    "        grads = tape.gradient(total_loss, vit_sub_model.trainable_variables)\n",
    "        # Clip gradients to prevent exploding gradients\n",
    "        grads = [tf.clip_by_norm(g, 1.0) if g is not None else None for g in grads]\n",
    "\n",
    "        # Check for NaN in gradients\n",
    "        if any([tf.reduce_any(tf.math.is_nan(g)) for g in grads if g is not None]):\n",
    "            print(f\"NaN detected in gradients at epoch {epoch+1}, step {step+1}\")\n",
    "            break\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, vit_sub_model.trainable_variables))\n",
    "        si_vit.accumulate_importance(vit_sub_model, grads)\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        train_macro_f1.update_state(batch_macro_f1)\n",
    "        train_loss.update_state(total_loss)\n",
    "\n",
    "        progress_bar.set_postfix({'loss': train_loss.result().numpy(), 'macro_f1': train_macro_f1.result().numpy()})\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    # Validation\n",
    "    val_macro_f1.reset_state()\n",
    "    val_loss.reset_state()\n",
    "    val_batches = len(X_val) // batch_size\n",
    "    val_progress_bar = tqdm(range(val_batches), desc='Validation', leave=False)\n",
    "    for step in val_progress_bar:\n",
    "        X_batch = X_val[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_val_sub[step*batch_size:(step+1)*batch_size]\n",
    "        preds = vit_sub_model(X_batch, training=False)\n",
    "        task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "        total_loss = task_loss\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        val_macro_f1.update_state(batch_macro_f1)\n",
    "        val_loss.update_state(total_loss)\n",
    "\n",
    "        val_progress_bar.set_postfix({'val_loss': val_loss.result().numpy(), 'val_macro_f1': val_macro_f1.result().numpy()})\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, '\n",
    "          f'Time: {epoch_time:.2f}s, '\n",
    "          f'Loss: {train_loss.result():.4f}, '\n",
    "          f'Macro F1: {train_macro_f1.result():.4f}, '\n",
    "          f'Val Loss: {val_loss.result():.4f}, '\n",
    "          f'Val Macro F1: {val_macro_f1.result():.4f}')\n",
    "\n",
    "    # Check for NaN in training loss\n",
    "    if tf.math.is_nan(train_loss.result()):\n",
    "        print(\"NaN detected in training loss. Stopping training.\")\n",
    "        break\n",
    "\n",
    "# After training, update omega\n",
    "si_vit.update_omega()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling and Publishing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN EWC Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.73      0.78      0.75       306\n",
      "       CLBBB       0.95      0.76      0.85        54\n",
      "       CRBBB       0.78      0.91      0.84        54\n",
      "       ILBBB       0.20      0.12      0.15         8\n",
      "         IMI       0.67      0.58      0.63       327\n",
      "       IRBBB       0.62      0.69      0.65       112\n",
      "        ISCA       0.43      0.32      0.37        93\n",
      "        ISCI       1.00      0.15      0.26        40\n",
      "        ISC_       0.73      0.38      0.50       128\n",
      "        IVCD       0.19      0.11      0.14        79\n",
      "   LAFB/LPFB       0.76      0.60      0.67       179\n",
      "     LAO/LAE       0.20      0.02      0.04        42\n",
      "         LMI       0.20      0.05      0.08        20\n",
      "         LVH       0.71      0.44      0.55       214\n",
      "        NORM       0.80      0.90      0.85       963\n",
      "        NST_       0.17      0.12      0.14        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.75      0.30      0.43        10\n",
      "         RVH       0.33      0.25      0.29        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.47      0.45      0.46       222\n",
      "         WPW       1.00      0.12      0.22         8\n",
      "        _AVB       0.49      0.21      0.29        82\n",
      "\n",
      "   micro avg       0.70      0.62      0.66      3034\n",
      "   macro avg       0.53      0.36      0.40      3034\n",
      "weighted avg       0.68      0.62      0.63      3034\n",
      " samples avg       0.68      0.67      0.66      3034\n",
      "\n",
      "CNN EWC Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.73      0.56      0.63       496\n",
      "         HYP       0.87      0.20      0.33       262\n",
      "          MI       0.82      0.57      0.68       550\n",
      "        NORM       0.88      0.59      0.71       963\n",
      "        STTC       0.83      0.46      0.59       521\n",
      "\n",
      "   micro avg       0.83      0.52      0.64      2792\n",
      "   macro avg       0.83      0.48      0.59      2792\n",
      "weighted avg       0.83      0.52      0.63      2792\n",
      " samples avg       0.59      0.54      0.55      2792\n",
      "\n",
      "ResNet EWC Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.65      0.73      0.69       306\n",
      "       CLBBB       0.95      0.65      0.77        54\n",
      "       CRBBB       0.85      0.93      0.88        54\n",
      "       ILBBB       0.20      0.12      0.15         8\n",
      "         IMI       0.62      0.66      0.64       327\n",
      "       IRBBB       0.60      0.45      0.51       112\n",
      "        ISCA       0.32      0.40      0.36        93\n",
      "        ISCI       0.47      0.17      0.25        40\n",
      "        ISC_       0.72      0.33      0.45       128\n",
      "        IVCD       0.26      0.09      0.13        79\n",
      "   LAFB/LPFB       0.75      0.67      0.71       179\n",
      "     LAO/LAE       0.00      0.00      0.00        42\n",
      "         LMI       0.22      0.10      0.14        20\n",
      "         LVH       0.84      0.38      0.52       214\n",
      "        NORM       0.80      0.84      0.82       963\n",
      "        NST_       0.12      0.03      0.04        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       1.00      0.10      0.18        10\n",
      "         RVH       0.33      0.08      0.13        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.39      0.39      0.39       222\n",
      "         WPW       1.00      0.38      0.55         8\n",
      "        _AVB       0.64      0.11      0.19        82\n",
      "\n",
      "   micro avg       0.68      0.59      0.63      3034\n",
      "   macro avg       0.51      0.33      0.37      3034\n",
      "weighted avg       0.66      0.59      0.60      3034\n",
      " samples avg       0.65      0.63      0.63      3034\n",
      "\n",
      "ResNet EWC Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.85      0.29      0.44       496\n",
      "         HYP       0.70      0.16      0.27       262\n",
      "          MI       0.76      0.34      0.47       550\n",
      "        NORM       0.94      0.11      0.19       963\n",
      "        STTC       0.90      0.18      0.31       521\n",
      "\n",
      "   micro avg       0.83      0.21      0.33      2792\n",
      "   macro avg       0.83      0.22      0.33      2792\n",
      "weighted avg       0.86      0.21      0.32      2792\n",
      " samples avg       0.23      0.19      0.20      2792\n",
      "\n",
      "ViT EWC Subdiagnostic Classification Report:\n",
      "\u001b[1m59/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.60      0.64      0.62       306\n",
      "       CLBBB       0.90      0.69      0.78        54\n",
      "       CRBBB       0.80      0.65      0.71        54\n",
      "       ILBBB       0.50      0.12      0.20         8\n",
      "         IMI       0.59      0.53      0.56       327\n",
      "       IRBBB       0.43      0.46      0.44       112\n",
      "        ISCA       0.24      0.17      0.20        93\n",
      "        ISCI       0.29      0.20      0.24        40\n",
      "        ISC_       0.56      0.44      0.49       128\n",
      "        IVCD       0.17      0.09      0.12        79\n",
      "   LAFB/LPFB       0.68      0.66      0.67       179\n",
      "     LAO/LAE       0.00      0.00      0.00        42\n",
      "         LMI       0.17      0.05      0.08        20\n",
      "         LVH       0.66      0.59      0.62       214\n",
      "        NORM       0.81      0.80      0.80       963\n",
      "        NST_       0.10      0.03      0.04        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.00      0.00      0.00        10\n",
      "         RVH       0.08      0.08      0.08        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.41      0.22      0.28       222\n",
      "         WPW       0.00      0.00      0.00         8\n",
      "        _AVB       0.09      0.06      0.07        82\n",
      "\n",
      "   micro avg       0.63      0.54      0.59      3034\n",
      "   macro avg       0.35      0.28      0.30      3034\n",
      "weighted avg       0.59      0.54      0.56      3034\n",
      " samples avg       0.59      0.59      0.57      3034\n",
      "\n",
      "ViT EWC Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.57      0.52      0.54       496\n",
      "         HYP       0.43      0.58      0.49       262\n",
      "          MI       0.59      0.57      0.58       550\n",
      "        NORM       0.77      0.75      0.76       963\n",
      "        STTC       0.65      0.52      0.58       521\n",
      "\n",
      "   micro avg       0.64      0.61      0.63      2792\n",
      "   macro avg       0.60      0.59      0.59      2792\n",
      "weighted avg       0.65      0.61      0.63      2792\n",
      " samples avg       0.60      0.63      0.59      2792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN EWC Subdiagnostic Classification Report:\")\n",
    "cnn_ewc_sub_report = evaluate_model(cnn_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"CNN EWC Superdiagnostic Classification Report:\")\n",
    "cnn_ewc_super_report = evaluate_model(cnn_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ResNet EWC Subdiagnostic Classification Report:\")\n",
    "resnet_ewc_sub_report = evaluate_model(resnet_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ResNet EWC Superdiagnostic Classification Report:\")\n",
    "resnet_ewc_super_report = evaluate_model(resnet_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ViT EWC Subdiagnostic Classification Report:\")\n",
    "vit_ewc_sub_report = evaluate_model(vit_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ViT EWC Superdiagnostic Classification Report:\")\n",
    "vit_ewc_super_report = evaluate_model(vit_super_model, X_test, y_test_super, classes_super)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN SI Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.73      0.78      0.75       306\n",
      "       CLBBB       0.95      0.76      0.85        54\n",
      "       CRBBB       0.78      0.91      0.84        54\n",
      "       ILBBB       0.20      0.12      0.15         8\n",
      "         IMI       0.67      0.58      0.63       327\n",
      "       IRBBB       0.62      0.69      0.65       112\n",
      "        ISCA       0.43      0.32      0.37        93\n",
      "        ISCI       1.00      0.15      0.26        40\n",
      "        ISC_       0.73      0.38      0.50       128\n",
      "        IVCD       0.19      0.11      0.14        79\n",
      "   LAFB/LPFB       0.76      0.60      0.67       179\n",
      "     LAO/LAE       0.20      0.02      0.04        42\n",
      "         LMI       0.20      0.05      0.08        20\n",
      "         LVH       0.71      0.44      0.55       214\n",
      "        NORM       0.80      0.90      0.85       963\n",
      "        NST_       0.17      0.12      0.14        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.75      0.30      0.43        10\n",
      "         RVH       0.33      0.25      0.29        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.47      0.45      0.46       222\n",
      "         WPW       1.00      0.12      0.22         8\n",
      "        _AVB       0.49      0.21      0.29        82\n",
      "\n",
      "   micro avg       0.70      0.62      0.66      3034\n",
      "   macro avg       0.53      0.36      0.40      3034\n",
      "weighted avg       0.68      0.62      0.63      3034\n",
      " samples avg       0.68      0.67      0.66      3034\n",
      "\n",
      "CNN SI Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.73      0.56      0.63       496\n",
      "         HYP       0.87      0.20      0.33       262\n",
      "          MI       0.82      0.57      0.68       550\n",
      "        NORM       0.88      0.59      0.71       963\n",
      "        STTC       0.83      0.46      0.59       521\n",
      "\n",
      "   micro avg       0.83      0.52      0.64      2792\n",
      "   macro avg       0.83      0.48      0.59      2792\n",
      "weighted avg       0.83      0.52      0.63      2792\n",
      " samples avg       0.59      0.54      0.55      2792\n",
      "\n",
      "ResNet SI Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.65      0.73      0.69       306\n",
      "       CLBBB       0.95      0.65      0.77        54\n",
      "       CRBBB       0.85      0.93      0.88        54\n",
      "       ILBBB       0.20      0.12      0.15         8\n",
      "         IMI       0.62      0.66      0.64       327\n",
      "       IRBBB       0.60      0.45      0.51       112\n",
      "        ISCA       0.32      0.40      0.36        93\n",
      "        ISCI       0.47      0.17      0.25        40\n",
      "        ISC_       0.72      0.33      0.45       128\n",
      "        IVCD       0.26      0.09      0.13        79\n",
      "   LAFB/LPFB       0.75      0.67      0.71       179\n",
      "     LAO/LAE       0.00      0.00      0.00        42\n",
      "         LMI       0.22      0.10      0.14        20\n",
      "         LVH       0.84      0.38      0.52       214\n",
      "        NORM       0.80      0.84      0.82       963\n",
      "        NST_       0.12      0.03      0.04        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       1.00      0.10      0.18        10\n",
      "         RVH       0.33      0.08      0.13        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.39      0.39      0.39       222\n",
      "         WPW       1.00      0.38      0.55         8\n",
      "        _AVB       0.64      0.11      0.19        82\n",
      "\n",
      "   micro avg       0.68      0.59      0.63      3034\n",
      "   macro avg       0.51      0.33      0.37      3034\n",
      "weighted avg       0.66      0.59      0.60      3034\n",
      " samples avg       0.65      0.63      0.63      3034\n",
      "\n",
      "ResNet SI Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.85      0.29      0.44       496\n",
      "         HYP       0.70      0.16      0.27       262\n",
      "          MI       0.76      0.34      0.47       550\n",
      "        NORM       0.94      0.11      0.19       963\n",
      "        STTC       0.90      0.18      0.31       521\n",
      "\n",
      "   micro avg       0.83      0.21      0.33      2792\n",
      "   macro avg       0.83      0.22      0.33      2792\n",
      "weighted avg       0.86      0.21      0.32      2792\n",
      " samples avg       0.23      0.19      0.20      2792\n",
      "\n",
      "ViT SI Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.60      0.64      0.62       306\n",
      "       CLBBB       0.90      0.69      0.78        54\n",
      "       CRBBB       0.80      0.65      0.71        54\n",
      "       ILBBB       0.50      0.12      0.20         8\n",
      "         IMI       0.59      0.53      0.56       327\n",
      "       IRBBB       0.43      0.46      0.44       112\n",
      "        ISCA       0.24      0.17      0.20        93\n",
      "        ISCI       0.29      0.20      0.24        40\n",
      "        ISC_       0.56      0.44      0.49       128\n",
      "        IVCD       0.17      0.09      0.12        79\n",
      "   LAFB/LPFB       0.68      0.66      0.67       179\n",
      "     LAO/LAE       0.00      0.00      0.00        42\n",
      "         LMI       0.17      0.05      0.08        20\n",
      "         LVH       0.66      0.59      0.62       214\n",
      "        NORM       0.81      0.80      0.80       963\n",
      "        NST_       0.10      0.03      0.04        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.00      0.00      0.00        10\n",
      "         RVH       0.08      0.08      0.08        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.41      0.22      0.28       222\n",
      "         WPW       0.00      0.00      0.00         8\n",
      "        _AVB       0.09      0.06      0.07        82\n",
      "\n",
      "   micro avg       0.63      0.54      0.59      3034\n",
      "   macro avg       0.35      0.28      0.30      3034\n",
      "weighted avg       0.59      0.54      0.56      3034\n",
      " samples avg       0.59      0.59      0.57      3034\n",
      "\n",
      "ViT SI Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.57      0.52      0.54       496\n",
      "         HYP       0.43      0.58      0.49       262\n",
      "          MI       0.59      0.57      0.58       550\n",
      "        NORM       0.77      0.75      0.76       963\n",
      "        STTC       0.65      0.52      0.58       521\n",
      "\n",
      "   micro avg       0.64      0.61      0.63      2792\n",
      "   macro avg       0.60      0.59      0.59      2792\n",
      "weighted avg       0.65      0.61      0.63      2792\n",
      " samples avg       0.60      0.63      0.59      2792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN SI Subdiagnostic Classification Report:\")\n",
    "cnn_si_sub_report = evaluate_model(cnn_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"CNN SI Superdiagnostic Classification Report:\")\n",
    "cnn_si_super_report = evaluate_model(cnn_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ResNet SI Subdiagnostic Classification Report:\")\n",
    "resnet_si_sub_report = evaluate_model(resnet_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ResNet SI Superdiagnostic Classification Report:\")\n",
    "resnet_si_super_report = evaluate_model(resnet_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ViT SI Subdiagnostic Classification Report:\")\n",
    "vit_si_sub_report = evaluate_model(vit_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ViT SI Superdiagnostic Classification Report:\")\n",
    "vit_si_super_report = evaluate_model(vit_super_model, X_test, y_test_super, classes_super)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Classification Performance:\n",
      "     Model                 Task  Macro F1-score\n",
      "0      CNN      Superdiagnostic        0.746157\n",
      "1   ResNet      Superdiagnostic        0.732267\n",
      "2      ViT      Superdiagnostic        0.667310\n",
      "3      CNN        Subdiagnostic        0.401320\n",
      "4   ResNet        Subdiagnostic        0.407258\n",
      "5      ViT        Subdiagnostic        0.282383\n",
      "6      CNN    EWC Subdiagnostic        0.397926\n",
      "7   ResNet    EWC Subdiagnostic        0.370305\n",
      "8      ViT    EWC Subdiagnostic        0.304643\n",
      "9      CNN  EWC Superdiagnostic        0.587815\n",
      "10  ResNet  EWC Superdiagnostic        0.334750\n",
      "11     ViT  EWC Superdiagnostic        0.591112\n",
      "12     CNN     SI Subdiagnostic        0.397926\n",
      "13  ResNet     SI Subdiagnostic        0.370305\n",
      "14     ViT     SI Subdiagnostic        0.304643\n",
      "15     CNN   SI Superdiagnostic        0.587815\n",
      "16  ResNet   SI Superdiagnostic        0.334750\n",
      "17     ViT   SI Superdiagnostic        0.591112\n"
     ]
    }
   ],
   "source": [
    "def get_macro_f1(report_dict):\n",
    "    return report_dict['macro avg']['f1-score']\n",
    "\n",
    "results = {\n",
    "    'Model': [],\n",
    "    'Task': [],\n",
    "    'Macro F1-score': []\n",
    "}\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['Superdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_super_report),\n",
    "    get_macro_f1(resnet_super_report),\n",
    "    get_macro_f1(vit_super_report)\n",
    "])\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['Subdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_sub_report),\n",
    "    get_macro_f1(resnet_sub_report),\n",
    "    get_macro_f1(vit_sub_report)\n",
    "])\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['EWC Subdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_ewc_sub_report),\n",
    "    get_macro_f1(resnet_ewc_sub_report),\n",
    "    get_macro_f1(vit_ewc_sub_report)\n",
    "])\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['EWC Superdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_ewc_super_report),\n",
    "    get_macro_f1(resnet_ewc_super_report),\n",
    "    get_macro_f1(vit_ewc_super_report)\n",
    "])\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['SI Subdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_si_sub_report),\n",
    "    get_macro_f1(resnet_si_sub_report),\n",
    "    get_macro_f1(vit_si_sub_report)\n",
    "])\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['SI Superdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_si_super_report),\n",
    "    get_macro_f1(resnet_si_super_report),\n",
    "    get_macro_f1(vit_si_super_report)\n",
    "])\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Classification Performance:\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
